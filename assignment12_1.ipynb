{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Assignment 12.1 - Recurrent Neural Networks\n",
    "\n",
    "Please submit your solution of this notebook in the Whiteboard at the corresponding Assignment entry as .ipynb-file and as .pdf.\n",
    "\n",
    "#### Please state both names of your group members here:\n",
    "Jane and John Doe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paola Gega, Daniel Thompson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 12.1.1: RNN - 'ShakesGen'\n",
    "\n",
    "Let's create a `ShakesGen` !!<br><br>\n",
    "The data folder contains a shakespeare folder with works from William Shakespeare. Your task is to implement an RNN that learns to write Shakespeare-style text.\n",
    "\n",
    "Below, you'll find all the utility code needed for this task. The Corpus class serves as a dataset, and you can retrieve a batch with its target by calling `get_batch` on a batchified dataset.\n",
    "\n",
    "* Build the missing model components and train your ShakesGen model. **(RESULT)**\n",
    "* Generate at least 30 lines of text using your ShakesGen model. **(RESULT)**\n",
    "\n",
    "Especially, if you train on cpu, you can stop training after 5 minutes and generate based on the current model state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/4000/0*WdbXF_e8kZI1R5nQ.png\" width=\"700\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://miro.medium.com/max/4000/0*WdbXF_e8kZI1R5nQ.png\", width=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.cuda as cuda\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dictionary(object):\n",
    "    def __init__(self):\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = []\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2idx:\n",
    "            self.idx2word.append(word)\n",
    "            self.word2idx[word] = len(self.idx2word) - 1\n",
    "        return self.word2idx[word]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx2word)\n",
    "\n",
    "\n",
    "class Corpus(object):\n",
    "    def __init__(self, path):\n",
    "        self.dictionary = Dictionary()\n",
    "        \n",
    "        # This is very english language specific\n",
    "        # We will ingest only these characters:\n",
    "        self.whitelist = [chr(i) for i in range(32, 127)]\n",
    "        \n",
    "        self.train = self.tokenize(os.path.join(path, 'train.txt'))\n",
    "        self.valid = self.tokenize(os.path.join(path, 'valid.txt'))\n",
    "\n",
    "    def tokenize(self, path):\n",
    "        \"\"\"Tokenizes a text file.\"\"\"\n",
    "        assert os.path.exists(path)\n",
    "        # Add words to the dictionary\n",
    "        with open(path, 'r',  encoding=\"utf8\") as f:\n",
    "            tokens = 0\n",
    "            for line in f:\n",
    "                line = ''.join([c for c in line if c in self.whitelist])\n",
    "                words = line.split() + ['<eos>']\n",
    "                tokens += len(words)\n",
    "                for word in words:\n",
    "                    self.dictionary.add_word(word)\n",
    "\n",
    "        # Tokenize file content\n",
    "        with open(path, 'r',  encoding=\"utf8\") as f:\n",
    "            ids = torch.LongTensor(tokens)\n",
    "            token = 0\n",
    "            for line in f:\n",
    "                line = ''.join([c for c in line if c in self.whitelist])\n",
    "                words = line.split() + ['<eos>']\n",
    "                for word in words:\n",
    "                    ids[token] = self.dictionary.word2idx[word]\n",
    "                    token += 1\n",
    "\n",
    "        return ids\n",
    "    \n",
    "def batchify(data, batch_size):\n",
    "    # Work out how cleanly we can divide the dataset into bsz parts.\n",
    "    nbatch = data.size(0) // batch_size\n",
    "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
    "    data = data.narrow(0, 0, nbatch * batch_size)\n",
    "    # Evenly divide the data across the bsz batches.\n",
    "    data = data.view(batch_size, -1).t().contiguous()\n",
    "    return data\n",
    "\n",
    "def get_batch(source, i, bptt_size=35):\n",
    "    seq_len = min(bptt_size, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+1:i+1+seq_len].view(-1)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download shakespeare dataset\n",
    "# !mkdir -p data/shakespeare\n",
    "# !wget -q -O data/shakespeare/train.txt https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
    "# !cp data/shakespeare/train.txt data/shakespeare/valid.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Corpus to load data\n",
    "corpus = Corpus('./data/shakespeare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25671\n",
      "First Citizen: <eos> Before we proceed any further, hear me speak. <eos> <eos> All: <eos> Speak, speak. <eos> <eos> First Citizen: <eos> You are all resolved rather to die than to famish? <eos> <eos> All: <eos> Resolved. resolved. <eos> <eos> First Citizen: <eos> First, you know Caius Marcius is chief enemy to the people. <eos> <eos> All: <eos> We know't, we know't. <eos> <eos> First Citizen: <eos> Let us kill him, and we'll have corn at our own price. <eos> Is't a verdict? <eos> <eos> All: <eos> No more talking on't; let it be done: away, away! <eos> <eos> Second\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(corpus.dictionary)\n",
    "print(vocab_size)\n",
    "\n",
    "# Print first 100 words from training data\n",
    "words = [corpus.dictionary.idx2word[corpus.train[i].item()] for i in range(min(100, len(corpus.train)))]\n",
    "print(' '.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of the word 'That': 409\n"
     ]
    }
   ],
   "source": [
    "idx = corpus.dictionary.word2idx.get(\"That\", -1)  # returns -1 if not found\n",
    "print(f\"Index of the word 'That': {idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tip: Use an Embedding layer to Tokenize each word.\n",
    "# e.g., self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "class ShakesGen(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers, dropout=0.5):\n",
    "        super(ShakesGen, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.rnn = nn.LSTM(embed_dim, hidden_dim, num_layers, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        x = self.dropout(x)\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        out = out.contiguous().view(-1, self.hidden_dim)\n",
    "        out = self.fc(out)\n",
    "        return out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        return (weight.new(self.num_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                weight.new(self.num_layers, batch_size, self.hidden_dim).zero_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 7.0446\n",
      "Epoch 2, Loss: 6.2002\n",
      "Epoch 3, Loss: 5.9119\n",
      "Epoch 4, Loss: 5.7078\n",
      "Epoch 5, Loss: 5.5243\n",
      "Validation Loss: 5.6488\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "embed_dim = 128\n",
    "hidden_dim = 256\n",
    "num_layers = 2\n",
    "dropout = 0.5\n",
    "batch_size = 20\n",
    "bptt_size = 35\n",
    "num_epochs = 5\n",
    "learning_rate = 0.002\n",
    "\n",
    "# Prepare data\n",
    "train_data = batchify(corpus.train, batch_size).to(device)\n",
    "valid_data = batchify(corpus.valid, batch_size).to(device)\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = ShakesGen(vocab_size, embed_dim, hidden_dim, num_layers, dropout).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    hidden = model.init_hidden(batch_size)\n",
    "    for i in range(0, train_data.size(0) - 1, bptt_size):\n",
    "        data, targets = get_batch(train_data, i, bptt_size)\n",
    "        optimizer.zero_grad()\n",
    "        output, hidden = model(data, hidden)\n",
    "        loss = criterion(output, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        # Detach hidden state to prevent backpropagating through entire history\n",
    "        hidden = tuple(h.detach() for h in hidden)\n",
    "    avg_loss = total_loss / (train_data.size(0) // bptt_size)\n",
    "    print(f'Epoch {epoch+1}, Loss: {avg_loss:.4f}')\n",
    "\n",
    "# Validation loop\n",
    "model.eval()\n",
    "total_loss = 0\n",
    "hidden = model.init_hidden(batch_size)\n",
    "with torch.no_grad():\n",
    "    for i in range(0, valid_data.size(0) - 1, bptt_size):\n",
    "        data, targets = get_batch(valid_data, i, bptt_size)\n",
    "        output, hidden = model(data, hidden)\n",
    "        loss = criterion(output, targets)\n",
    "        total_loss += loss.item()\n",
    "        hidden = tuple(h.detach() for h in hidden)\n",
    "    avg_loss = total_loss / (valid_data.size(0) // bptt_size)\n",
    "    print(f'Validation Loss: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lords: and keen enter their death's grow. but addle\n",
      "Or so. of before what still Italy death,\n",
      "Who made their quarrel? tires Jupiter\n",
      "Or late in the wounds' part,\n",
      "protest, middle the summer, but banish'd proud;\n",
      "And Romeo hang. along; and but kings flight\n",
      "The brother weeping be to of news.\n",
      "\n",
      "JULIET:\n",
      "Marry, me he have tied thou shalt of methinks,\n",
      "Of like them: by rise, the highness\n",
      "Sharp it being speak stand perchance, to my many-headed\n",
      "Plantagenet, for no overta'en is and say\n",
      "So.\n",
      "With absolute his false wife to learn of?\n",
      "Till from have so have go myself\n",
      "Who make thy wife's wish of wine, I to it.\n",
      "As thou be Edward, to be sweet look'd\n",
      "To Luke's allow'd where when be thee\n",
      "We friar, what fantastic to stifle and you the cloaks;\n",
      "Unless we have swiftness, we have sign\n",
      "Ye dost are approach.\n",
      "Thy enrolled fellow between and a eyes and I not met\n",
      "\n",
      "QUEEN ELIZABETH:\n",
      "Put choosing what's thou English winking\n",
      "\n",
      "KING BOLINGBROKE:\n",
      "Woe hand, Isabel? like your despair?\n",
      "here? are our lingering and back, is thee,\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "num_lines = 30\n",
    "max_length = 20  # max words per line\n",
    "input_word = '<eos>'\n",
    "hidden = model.init_hidden(1)\n",
    "with torch.no_grad():\n",
    "    for _ in range(num_lines):\n",
    "        line = []\n",
    "        for _ in range(max_length):\n",
    "            input_idx = torch.tensor([[corpus.dictionary.word2idx[input_word]]]).to(device)\n",
    "            output, hidden = model(input_idx, hidden)\n",
    "            prob = F.softmax(output[-1], dim=0).data\n",
    "            word_idx = torch.multinomial(prob, 1)[0].item()\n",
    "            input_word = corpus.dictionary.idx2word[word_idx]\n",
    "            if input_word == '<eos>':\n",
    "                break\n",
    "            line.append(input_word)\n",
    "        print(' '.join(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Congratz, you made it! :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
