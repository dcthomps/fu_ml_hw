{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4.1 - PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please submit your solution of this notebook in the Whiteboard at the corresponding Assignment entry as .ipynb-file and as .pdf. <br><br>\n",
    "Please do **NOT** rename the file!\n",
    "\n",
    "#### State both names of your group members here:\n",
    "[Jane and John Doe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daniel Thompson, Paola Gega"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Grading Info/Details - Assignment 4.1:\n",
    "\n",
    "The assignment will be graded semi-automatically, which means that your code will be tested against a set of predefined test cases and qualitatively assessed by a human. This will speed up the grading process for us.\n",
    "\n",
    "* For passing the test scripts: \n",
    "    - Please make sure to **NOT** alter predefined class or function names, as this would lead to failing of the test scripts.\n",
    "    - Please do **NOT** rename the files before uploading to the Whiteboard!\n",
    "\n",
    "* **(RESULT)** tags indicate checkpoints that will be specifically assessed by a human.\n",
    "\n",
    "* You will pass the assignment if you pass the majority of test cases and we can at least confirm effort regarding the **(RESULT)**-tagged checkpoints per task.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.1.1 - PCA from Scratch\n",
    "\n",
    "Implement Principal Component Analysis (PCA) from scratch using only `NumPy`.\n",
    "This assignment will help you understand the mathematical foundations of PCA.\n",
    "\n",
    "* Implement the PCA given the class structure below. **(RESULT)**\n",
    "* Test your implementation using small synthetic datasets described in the test functions below. **(RESULT)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA:\n",
    "    \"\"\"\n",
    "    Principal Component Analysis implementation using only NumPy.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_components=2):\n",
    "        \"\"\"\n",
    "        Initialize PCA.\n",
    "        \"\"\"\n",
    "        self.n_components = n_components\n",
    "        self.explained_variance_ = None\n",
    "        self.mean_ = None\n",
    "        self.stds_ = None\n",
    "        self.transformation_ = None\n",
    "        \n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Fit PCA on the training data X.\n",
    "        \"\"\"\n",
    "        # First we normalize the features of X\n",
    "        self.mean_ = X.mean(axis=0)\n",
    "        self.stds_ = X.std(axis=0)\n",
    "        self.stds_[self.stds_ == 0] = 1 # Prevent division by zero for constant features\n",
    "        X = (X-self.mean_)/self.stds_\n",
    "\n",
    "        cov = np.cov(X.T)\n",
    "        S, W = np.linalg.eig(cov)\n",
    "        sorted_indices = np.argsort(S)[::-1]\n",
    "        self.explained_variance_ = S[sorted_indices]\n",
    "        W_sorted = W[:,sorted_indices]\n",
    "        self.transformation_ = W_sorted[:, :self.n_components]\n",
    "    \n",
    "    def transform(self, X, dim=5):\n",
    "        \"\"\"\n",
    "        Transform X into the principal component space.\n",
    "        \"\"\"\n",
    "        projected_data = np.dot(X, self.transformation_)\n",
    "        return projected_data\n",
    "    \n",
    "    def inverse_transform(self, X):\n",
    "        \"\"\"\n",
    "        Transform data back to original space.\n",
    "        \"\"\"\n",
    "        reconstructed_data = np.dot(X, self.transformation_.T) * self.stds_ + self.mean_\n",
    "        return reconstructed_data\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        \"\"\"\n",
    "        Fit PCA and transform X in one step.\n",
    "        \"\"\"\n",
    "        self.fit(X)\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_basic_pca():\n",
    "    \"\"\"Test 1: Basic PCA on 2D data\"\"\"\n",
    "    # TODO: Implement this function\n",
    "    pass\n",
    "\n",
    "\n",
    "def test_dimensionality_reduction():\n",
    "    \"\"\"Test 2: Reduce 5D data to 2D\"\"\"\n",
    "    # TODO: Implement this function\n",
    "    pass\n",
    "\n",
    "\n",
    "def test_reconstruction():\n",
    "    \"\"\"Test 3: Inverse transform (reconstruction)\"\"\"\n",
    "    # TODO: Implement this function\n",
    "    pass\n",
    "\n",
    "\n",
    "def test_variance_ordering():\n",
    "    \"\"\"Test 4: Components are ordered by variance\"\"\"\n",
    "    print(\"Test 4: Verify components are ordered by explained variance\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    X = np.random.randn(100, 5)\n",
    "    \n",
    "    pca = PCA(n_components=5)\n",
    "    pca.fit(X)\n",
    "    \n",
    "    # Check that explained variances are in descending order\n",
    "    variances = pca.explained_variance_\n",
    "    is_sorted = np.all(variances[:-1] >= variances[1:])\n",
    "    \n",
    "    print(f\"Explained variances: {variances}\")\n",
    "    print(f\"Is sorted (descending): {is_sorted}\")\n",
    "    assert is_sorted, \"Components not sorted by variance!\"\n",
    "    print(\"✓ Test 4 passed\\n\")\n",
    "\n",
    "\n",
    "def test_centered_data():\n",
    "    \"\"\"Test 5: Verify data is properly centered\"\"\"\n",
    "    print(\"Test 5: Verify data centering\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    X = np.random.randn(100, 3) + 10  # Add offset\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(X)\n",
    "    \n",
    "    # Mean should be close to the original data mean\n",
    "    print(f\"Original data mean: {np.mean(X, axis=0)}\")\n",
    "    print(f\"Stored mean: {pca.mean_}\")\n",
    "    print(f\"Difference: {np.mean(np.abs(np.mean(X, axis=0) - pca.mean_)):.10f}\")\n",
    "    print(\"✓ Test 5 passed\\n\")\n",
    "\n",
    "\n",
    "def run_all_tests():\n",
    "    print(\"Running PCA test suite...\\n\")\n",
    "    try:\n",
    "        test_basic_pca()\n",
    "        test_dimensionality_reduction()\n",
    "        test_reconstruction()\n",
    "        test_variance_ordering()\n",
    "        test_centered_data()\n",
    "        \n",
    "        print(\"ALL TESTS PASSED!\")\n",
    "        \n",
    "    except AssertionError as e:\n",
    "        print(f\"\\n❌ Test failed: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Unexpected error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCA test suite...\n",
      "\n",
      "Test 4: Verify components are ordered by explained variance\n",
      "Explained variances: [1.29838276 1.07436197 0.98728909 0.93219883 0.75827241]\n",
      "Is sorted (descending): True\n",
      "✓ Test 4 passed\n",
      "\n",
      "Test 5: Verify data centering\n",
      "Original data mean: [10.09176598  9.81676669 10.07482166]\n",
      "Stored mean: [10.09176598  9.81676669 10.07482166]\n",
      "Difference: 0.0000000000\n",
      "✓ Test 5 passed\n",
      "\n",
      "ALL TESTS PASSED!\n"
     ]
    }
   ],
   "source": [
    "# Run the test suite\n",
    "run_all_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.1.2 - PCA on Real-World Data\n",
    "\n",
    "* Apply your PCA implementation on the `California Housing Dataset`. **(RESULT)**\n",
    "* Compare your results with those obtained from the scikit-learn PCA implementation: `sklearn.decomposition.PCA`. Are your results within numerical precision? **(RESULT)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.decomposition import PCA as SklearnPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Congratz, you made it! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
