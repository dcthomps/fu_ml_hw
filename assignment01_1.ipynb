{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1.1 - k-Nearest Neighbor (kNN)\n",
    "\n",
    "Dear students, you have successfully cloned the repo. Great! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course Assignment Guidelines\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Weekly Assignment Structure\n",
    "\n",
    "Each week includes **two assignments**:\n",
    "\n",
    "| File Format | Required For |\n",
    "|-------------|--------------|\n",
    "| `assignment[x]_1.ipynb` | All students |\n",
    "| `assignment[x]_2.ipynb` | 10 ECTS students only |\n",
    "\n",
    "Upload your solution as a `.ipynb` file **AND** a `.pdf` file in the respective entry in the whiteboard. You will find each deadline there as well.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Grading Requirements\n",
    "\n",
    "### Pass/Fail System\n",
    "* Each submitted `.ipynb` notebook receives either a **\"pass\"** or **\"fail\"** grade\n",
    "* **Minimum # of passes: n-1** \n",
    "\n",
    "### Separate Tracking\n",
    "The n-1 # of passes is tracked **separately** for each assignment type:\n",
    "\n",
    "#### For 5 ECTS Students:\n",
    "- ‚úîÔ∏è Must achieve n-1 # of passes on `assignment[x]_1.ipynb` series\n",
    "\n",
    "#### For 10 ECTS Students:\n",
    "- ‚úîÔ∏è Must achieve n-1 # of passes on `assignment[x]_1.ipynb` series\n",
    "- ‚úîÔ∏è Must achieve n-1 # of passes on `assignment[x]_2.ipynb` series\n",
    "\n",
    "---\n",
    "\n",
    "## üåü BONUS Tasks\n",
    "\n",
    "- **Optional BONUS tasks** appear in some notebooks\n",
    "- Successfully completing **BONUS** tasks earns **extra points** toward your final grade\n",
    "- Check the **Whiteboard** assignment grading for bonus point confirmations\n",
    "- 10 ECTS students will find separate bonus tasks in `assignment[x]_2.ipynb`\n",
    "- 5 ECTS students will **NOT** get additional extra points for solving `assignment[x]_2.ipynb` Bonus tasks\n",
    "- Vice Versa: 10 ECTS students will **NOT** get additional extra points for solving `assignment[x]_1.ipynb` Bonus tasks\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Quick Summary\n",
    "\n",
    "| Study Program | Requirements | Pass Criteria |\n",
    "|---------------|-------------|---------------|\n",
    "| **5 ECTS** | `assignment[x]_1.ipynb` | n-1 |\n",
    "| **10 ECTS** | `assignment[x]_1.ipynb` + `assignment[x]_2.ipynb` | n-1 each |\n",
    "| **All Students** | Optional BONUS tasks | Extra final exam points |\n",
    "\n",
    "\n",
    "**Note:** The n-1 rule is mandatory to pass the tutorial component of the module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please submit your solution of this notebook in the Whiteboard at the corresponding Assignment entry as .ipynb-file and as .pdf. <br><br>\n",
    "Please do **NOT** rename the file!\n",
    "\n",
    "#### State both names of your group members here:\n",
    "[Paola Gega and Daniel Thompson]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading Info/Details - Assignment 1.1:\n",
    "\n",
    "The assignment will be graded semi-automatically, which means that your code will be tested against a set of predefined test cases and qualitatively assessed by a human. This will speed up the grading process for us.\n",
    "\n",
    "* For passing the test scripts: \n",
    "    - Please make sure to **NOT** alter predefined class or function names, as this would lead to failing of the test scripts.\n",
    "    - Please do **NOT** rename the files before uploading to the Whiteboard!\n",
    "\n",
    "* **(RESULT)** tags indicate checkpoints that will be specifically assessed by a human.\n",
    "\n",
    "* You will pass the assignment if you pass the majority of test cases and we can at least confirm effort regarding the **(RESULT)**-tagged checkpoints per task.\n",
    "\n",
    "Note: For now, we will keep the test cases black-boxed, meaning we won't reveal their internal implementation details. This might be subject to change in the future, depending on how well we can keep up writing test cases for upcoming assignments which are still work in progress. (:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your tasks start from here. :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.1.1 - kNN on Iris Dataset\n",
    "\n",
    "Implement the k-Nearest Neighbor (kNN) algorithm from scratch using only NumPy. <br><br> You may use the provided sklearn functions to load datasets and evaluate your results. Use the [Iris dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html) for training and testing your model. \n",
    "\n",
    "* Plot 2 samples per class to check on the data. **(RESULT)**\n",
    "* Split the dataset into a training set (80%) and a test set (20%). Train your model on the training set and evaluate it on the test set using the accuracy score as a metric. Try at least 3 different values for k (e.g., 1, 3, 5) and report the results. **(RESULT)**\n",
    "\n",
    "Note: Feature normalization might help to improve your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "iris = load_iris()\n",
    "# standardize features (i.e., columns) so they have mean zero and variance 1\n",
    "X = iris['data']\n",
    "means = X.mean(axis=0)\n",
    "std = X.std(axis=0)\n",
    "X_z_norm = (X-means)/std\n",
    "\n",
    "# TODO: Plot 2 samples per class to check on the data.\n",
    "# Don't know if better to do this with the raw data or after feature normalization\n",
    "# Best would be to use principal component analysis but no time for that!\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_z_norm, iris['target'], test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNClassifier:    # Do not rename\n",
    "    \"\"\"K-Nearest Neighbors classifier using only NumPy.\"\"\"\n",
    "    \n",
    "    def __init__(self, k):\n",
    "        \"\"\"Initialize KNN classifier, providing k and the training data.\"\"\"\n",
    "        self.k = k\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the model using the training data.\"\"\"\n",
    "        \"\"\"Store the data as a single augmented matrix.\"\"\"\n",
    "        self.X_augmented = np.hstack([X,y[:,np.newaxis]])\n",
    "\n",
    "    def neighbors(self, X):\n",
    "        \"\"\"Sort training set by Euclidean distance to X\"\"\"\n",
    "        \"\"\"Return numpy array corresponding to the augmented matrix of the k closest feature vectors along with corresponding classes\"\"\"\n",
    "        \"\"\"Working with the augmented matrix allows us to keep track of the labels while we sort.\"\"\"\n",
    "        # TODO: Implement this function\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict classes for multiple samples.\"\"\"\n",
    "        k_neighbors = self.neighbors(X)\n",
    "        labels = k_neighbors[:,-1]\n",
    "        \"\"\"Return most common lable occuring in the array labels\"\"\"\n",
    "        n = np.argmax([np.sum(labels == l) for l in labels])\n",
    "        return labels[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in [4,7,10]:\n",
    "    KNN = KNNClassifier(k)\n",
    "    KNN.fit(X_train, y_train)\n",
    "    y_test_hat = KNN.predict(X_test)\n",
    "    # calculate accuracy as proportion of test set correctly labled\n",
    "    print(\"Proportion of test set correctly predicted for k={}:\".format(k), np.sum(y_test_hat == y_test) / len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.1.2 - kNN on MNIST Dataset\n",
    "\n",
    "* Run your NumPy-based kNN implementation on the [MNIST dataset](https://www.wikiwand.com/en/articles/MNIST_database). **(RESULT)** \n",
    "* Report the accuracy of your model on a 20% test split and compare a k = {1,3}. **(RESULT)**\n",
    "* Visualize 3 misclassified images. **(RESULT)**\n",
    "\n",
    "Note: You may want touse a subset of the MNIST dataset to reduce computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "def load_mnist_subset(n_train=5000, n_test=1000):\n",
    "    \"\"\"Load a subset of MNIST dataset for faster computation.\"\"\"\n",
    "    # Load MNIST from OpenML\n",
    "    mnist = fetch_openml('mnist_784', version=1, cache=True, parser='auto', as_frame=False)\n",
    "    \n",
    "    # TODO\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Congratz, you made it! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyforecast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
