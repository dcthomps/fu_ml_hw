{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1.1 - k-Nearest Neighbor (kNN)\n",
    "\n",
    "Dear students, you have successfully cloned the repo. Great! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course Assignment Guidelines\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Weekly Assignment Structure\n",
    "\n",
    "Each week includes **two assignments**:\n",
    "\n",
    "| File Format | Required For |\n",
    "|-------------|--------------|\n",
    "| `assignment[x]_1.ipynb` | All students |\n",
    "| `assignment[x]_2.ipynb` | 10 ECTS students only |\n",
    "\n",
    "Upload your solution as a `.ipynb` file **AND** a `.pdf` file in the respective entry in the whiteboard. You will find each deadline there as well.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Grading Requirements\n",
    "\n",
    "### Pass/Fail System\n",
    "* Each submitted `.ipynb` notebook receives either a **\"pass\"** or **\"fail\"** grade\n",
    "* **Minimum # of passes: n-1** \n",
    "\n",
    "### Separate Tracking\n",
    "The n-1 # of passes is tracked **separately** for each assignment type:\n",
    "\n",
    "#### For 5 ECTS Students:\n",
    "- ‚úîÔ∏è Must achieve n-1 # of passes on `assignment[x]_1.ipynb` series\n",
    "\n",
    "#### For 10 ECTS Students:\n",
    "- ‚úîÔ∏è Must achieve n-1 # of passes on `assignment[x]_1.ipynb` series\n",
    "- ‚úîÔ∏è Must achieve n-1 # of passes on `assignment[x]_2.ipynb` series\n",
    "\n",
    "---\n",
    "\n",
    "## üåü BONUS Tasks\n",
    "\n",
    "- **Optional BONUS tasks** appear in some notebooks\n",
    "- Successfully completing **BONUS** tasks earns **extra points** toward your final grade\n",
    "- Check the **Whiteboard** assignment grading for bonus point confirmations\n",
    "- 10 ECTS students will find separate bonus tasks in `assignment[x]_2.ipynb`\n",
    "- 5 ECTS students will **NOT** get additional extra points for solving `assignment[x]_2.ipynb` Bonus tasks\n",
    "- Vice Versa: 10 ECTS students will **NOT** get additional extra points for solving `assignment[x]_1.ipynb` Bonus tasks\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Quick Summary\n",
    "\n",
    "| Study Program | Requirements | Pass Criteria |\n",
    "|---------------|-------------|---------------|\n",
    "| **5 ECTS** | `assignment[x]_1.ipynb` | n-1 |\n",
    "| **10 ECTS** | `assignment[x]_1.ipynb` + `assignment[x]_2.ipynb` | n-1 each |\n",
    "| **All Students** | Optional BONUS tasks | Extra final exam points |\n",
    "\n",
    "\n",
    "**Note:** The n-1 rule is mandatory to pass the tutorial component of the module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please submit your solution of this notebook in the Whiteboard at the corresponding Assignment entry as .ipynb-file and as .pdf. <br><br>\n",
    "Please do **NOT** rename the file!\n",
    "\n",
    "#### State both names of your group members here:\n",
    "[Paola Gega and Daniel Thompson]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daniel Thompson and Paola Gega"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading Info/Details - Assignment 1.1:\n",
    "\n",
    "The assignment will be graded semi-automatically, which means that your code will be tested against a set of predefined test cases and qualitatively assessed by a human. This will speed up the grading process for us.\n",
    "\n",
    "* For passing the test scripts: \n",
    "    - Please make sure to **NOT** alter predefined class or function names, as this would lead to failing of the test scripts.\n",
    "    - Please do **NOT** rename the files before uploading to the Whiteboard!\n",
    "\n",
    "* **(RESULT)** tags indicate checkpoints that will be specifically assessed by a human.\n",
    "\n",
    "* You will pass the assignment if you pass the majority of test cases and we can at least confirm effort regarding the **(RESULT)**-tagged checkpoints per task.\n",
    "\n",
    "Note: For now, we will keep the test cases black-boxed, meaning we won't reveal their internal implementation details. This might be subject to change in the future, depending on how well we can keep up writing test cases for upcoming assignments which are still work in progress. (:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your tasks start from here. :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.1.1 - kNN on Iris Dataset\n",
    "\n",
    "Implement the k-Nearest Neighbor (kNN) algorithm from scratch using only NumPy. <br><br> You may use the provided sklearn functions to load datasets and evaluate your results. Use the [Iris dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html) for training and testing your model. \n",
    "\n",
    "* Plot 2 samples per class to check on the data. **(RESULT)**\n",
    "* Split the dataset into a training set (80%) and a test set (20%). Train your model on the training set and evaluate it on the test set using the accuracy score as a metric. Try at least 3 different values for k (e.g., 1, 3, 5) and report the results. **(RESULT)**\n",
    "\n",
    "Note: Feature normalization might help to improve your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "iris = load_iris()\n",
    "# standardize features (i.e., columns) so they have mean zero and variance 1\n",
    "X = iris['data']\n",
    "# means = X.mean(axis=0)\n",
    "# std = X.std(axis=0)\n",
    "# X_z_norm = (X-means)/std\n",
    "\n",
    "# Don't know if better to do this with the raw data or after feature normalization\n",
    "# Best would be to use principal component analysis but no time for that! so instead making one plot for first two dimensions and one for last two\n",
    "\n",
    "# should we also remove outliers?\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(projection='3d')\n",
    "# ax.scatter(iris['data'][:, 0], iris['data'][:, 1], iris['data'][:, 2], c=iris['target'])\n",
    "indices_0 = np.array(np.random.choice(50, 2, replace=False)) # generate 2 random indices for class 0\n",
    "indices_1 = np.array(np.random.choice(np.arange(50,100), 2, replace=False)) # generate 2 random indices for class 1\n",
    "indices_2 = np.array(np.random.choice(np.arange(100,150), 2, replace=False)) # generate 2 random indices for class 2\n",
    "\n",
    "plot_instances = np.vstack((iris['data'][indices_0],iris['data'][indices_1],iris['data'][indices_2])) # stack all values picked from the dataset\n",
    "plot_labels = np.vstack((iris['target'][indices_0],iris['target'][indices_1],iris['target'][indices_2])) # stack according class labels\n",
    "\n",
    "plot_1 = plt.subplot(1, 2, 1)\n",
    "plt.scatter(plot_instances[:, 0], plot_instances[:, 1], c=plot_labels)\n",
    "\n",
    "plot_1.set_xlabel('sepal length in cm')\n",
    "plot_1.set_ylabel('sepal width in cm')\n",
    "\n",
    "plot_2 = plt.subplot(1, 2, 2)\n",
    "plt.scatter(plot_instances[:, 2], plot_instances[:, 3], c=plot_labels)\n",
    "\n",
    "plot_2.set_xlabel('petal length in cm')\n",
    "plot_2.set_ylabel('petal width in cm')\n",
    "\n",
    "plt.show\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris['data'], iris['target'], test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNClassifier:    # Do not rename\n",
    "    \"\"\"K-Nearest Neighbors classifier using only NumPy.\"\"\"\n",
    "    \n",
    "    def __init__(self, k):\n",
    "        \"\"\"Initialize KNN classifier, providing k and the training data.\"\"\"\n",
    "        self.k = k\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the model using the training data.\"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"Predict classes for multiple samples.\"\"\"\n",
    "        n_test = len(X_test)\n",
    "        NN = np.empty(n_test, self.k+1), dtype=int) # initialise nearest neighbours label array with one column (+1) for the winner label\n",
    "        \n",
    "        for i in np.arange(n_test): # go through test samples\n",
    "            euc_dist = np.linalg.norm(self.X - X_test[i], axis=1) # compute distance of every training sample to test sample at hand\n",
    "            sorted_ind = np.argsort(euc_dist) # sort the resulting distances\n",
    "            for l in np.arange(self.k): \n",
    "                NN[i,l] = self.y[sorted_ind[l]] # look up the labels of the k closest neighbours and store\n",
    "\n",
    "        \"\"\"Return most common label occuring in the array labels\"\"\"\n",
    "        for i in np.arange(n_test):\n",
    "            labels, count = np.unique(NN[i][:-1], return_counts=True)\n",
    "            NN[i][-1]= labels[np.argmax(count)] # majority voting in this case is okay because the class distribution is not skewed (50 samples of each class)\n",
    "\n",
    "        return NN[:,-1]\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in [4,15,31]:\n",
    "    KNN = KNNClassifier(k)\n",
    "    KNN.fit(X_train, y_train)\n",
    "    y_test_hat = KNN.predict(X_test)\n",
    "    # calculate accuracy as proportion of test set correctly labeled\n",
    "    print(\"Proportion of test set correctly predicted for k={}:\".format(k), np.sum(y_test_hat == y_test) / len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.1.2 - kNN on MNIST Dataset\n",
    "\n",
    "* Run your NumPy-based kNN implementation on the [MNIST dataset](https://www.wikiwand.com/en/articles/MNIST_database). **(RESULT)** \n",
    "* Report the accuracy of your model on a 20% test split and compare a k = {1,3}. **(RESULT)**\n",
    "* Visualize 3 misclassified images. **(RESULT)**\n",
    "\n",
    "Note: You may want touse a subset of the MNIST dataset to reduce computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "def load_mnist_subset(n_train=5000, n_test=1000):\n",
    "    \"\"\"Load a subset of MNIST dataset for faster computation.\"\"\"\n",
    "    # Load MNIST from OpenML\n",
    "    mnist = fetch_openml('mnist_784', version=1, cache=True, parser='auto', as_frame=False)\n",
    "    random_indices = np.array(np.random.choice(n_train+n_test, n_train+n_test, replace=False)) # generate 6000 (default) random indices to form the subset\n",
    "    mnist_x_subset = mnist['data'][random_indices] # pick out the corresponding samples x\n",
    "    mnist_y_subset = [int(y) for y in mnist['target'][random_indices]] # pick out the corresponding labels y\n",
    "    \n",
    "    return train_test_split(mnist_x_subset , mnist_y_subset, test_size=n_test/n_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_mnist_subset()\n",
    "\n",
    "for k in [1,3]:\n",
    "    KNN = KNNClassifier(k)\n",
    "    KNN.fit(X_train, y_train)\n",
    "    y_test_hat = KNN.predict(X_test)\n",
    "    # calculate accuracy as proportion of test set correctly labeled\n",
    "    print(\"Proportion of test set correctly predicted for k={}:\".format(k), np.sum(y_test_hat == y_test) / len(y_test))\n",
    "\n",
    "count = 0\n",
    "for i in range(len(y_test)):\n",
    "    if y_test_hat[i] != y_test[i]:\n",
    "        plt.imshow(X_test[i].reshape(28,28), cmap='gray')\n",
    "        plt.title(\"Predicted: {}, True: {}\".format(y_test_hat[i], y_test[i]))\n",
    "        plt.show()\n",
    "        count += 1\n",
    "    if count == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Congratz, you made it! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyforecast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
