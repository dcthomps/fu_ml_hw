{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2.1 - Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please submit your solution of this notebook in the Whiteboard at the corresponding Assignment entry as .ipynb-file and as .pdf. <br><br>\n",
    "Please do **NOT** rename the file!\n",
    "\n",
    "#### State both names of your group members here:\n",
    "[Jane and John Doe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daniel Thompson and Paola Gega"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading Info/Details - Assignment 2.1:\n",
    "\n",
    "The assignment will be graded semi-automatically, which means that your code will be tested against a set of predefined test cases and qualitatively assessed by a human. This will speed up the grading process for us.\n",
    "\n",
    "* For passing the test scripts: \n",
    "    - Please make sure to **NOT** alter predefined class or function names, as this would lead to failing of the test scripts.\n",
    "    - Please do **NOT** rename the files before uploading to the Whiteboard!\n",
    "\n",
    "* **(RESULT)** tags indicate checkpoints that will be specifically assessed by a human.\n",
    "\n",
    "* You will pass the assignment if you pass the majority of test cases and we can at least confirm effort regarding the **(RESULT)**-tagged checkpoints per task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.1.1 - kMeans\n",
    "\n",
    "kMeans is an unsupervised learning algorithm that partitions n observations into k clusters. Each observation belongs to the cluster with the nearest mean (cluster center or centroid).\n",
    "\n",
    "\n",
    "### 1. kMeans Implementation\n",
    "* Implement the kMeans clustering algorithm using `numpy` only. Use the `KMeans` class structure below. **(RESULT)**\n",
    "* Test the convergence of your implementation by creating a 2D synthetic dataset yourself. Report on the convergence. **(RESULT)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans:\n",
    "    def __init__(self, k=3, max_iters=100, tol=1e-4, random_state=None):\n",
    "        \"\"\"\n",
    "        Initialize KMeans clusterer.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        k : int\n",
    "            Number of clusters\n",
    "        max_iters : int\n",
    "            Maximum number of iterations\n",
    "        tol : float\n",
    "            Tolerance for convergence (change in centroids)\n",
    "        random_state : int or None\n",
    "            Random seed for reproducibility\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.max_iters = max_iters\n",
    "        self.tol = tol\n",
    "        self.random_state = random_state\n",
    "        self.labels_ = None\n",
    "\n",
    "    def euclidean_distance_vectorized(self, X_1, X_2):\n",
    "            \"\"\"\n",
    "            Vectorized computation of Euclidean distances.\n",
    "            More efficient for multiple test samples.\n",
    "\n",
    "            Parameters:\n",
    "            X_1 (ndarray): Test samples of shape (n_1, m)\n",
    "            X_2 (ndarray): Test samples of shape (n_2, m)\n",
    "\n",
    "            Returns:\n",
    "            ndarray: Distance matrix of shape (n_1, n_2)\n",
    "            \"\"\"\n",
    "            # Using broadcasting for efficient computation\n",
    "            # ||X_1 - X_2||^2 = ||X_1||^2 + ||X_2||^2 - 2*X_1Â·X_2\n",
    "\n",
    "            # X_1 - SHAPE (n_1, m)\n",
    "            # X_2 - SHAPE (n_2, m)\n",
    "            X_1_sqnorms = np.sum(X_1**2, axis=1, keepdims=True)  # (n_1, 1)\n",
    "            X_2_sqnorms = np.sum(X_2**2, axis=1)  # (n_2, 1)\n",
    "            dots = np.dot(X_1, X_2.T)  # (n_1, n_2)\n",
    "\n",
    "            distances = np.sqrt(X_1_sqnorms + X_2_sqnorms - 2 * dots)  # X_1_sqnorms + X_2_sqnorms - broadcasted addition (n_1, n_2)\n",
    "            distances[np.isnan(distances)] = 0\n",
    "            return distances  # SHAPE (n_1, n_2)\n",
    "\n",
    "    \n",
    "    def initialize_centroids(self, X):\n",
    "        \"\"\"\n",
    "        Initialize cluster centers using random selection from data points.\n",
    "        \"\"\"\n",
    "        n = len(X)\n",
    "        self.labels_ = np.empty(n, dtype=int)\n",
    "        # Choose k distinct random points from the data to use for the first step of the algorithm\n",
    "        rng = np.random.default_rng(seed=self.random_state)\n",
    "        inds = rng.choice(n, self.k, replace=False)\n",
    "        self.centroids = np.empty((self.k, len(X[0])), dtype=float)\n",
    "        self.centroids = X[inds]\n",
    "    \n",
    "    def initialize_centroids_plusplus(self, X): # for the following Subtask\n",
    "        n = len(X)\n",
    "        self.labels_ = np.empty(n, dtype=int)\n",
    "        rng = np.random.default_rng(seed=self.random_state)\n",
    "        # Initialize first centroid\n",
    "        self.centroids = X[rng.choice(n, 1)]\n",
    "        count = 1\n",
    "        # Draw subsequent centroid points according to knn++ algorithm\n",
    "        while count < self.k:\n",
    "            distances = self.euclidean_distance_vectorized(X, self.centroids)\n",
    "            # Construct a vector of probability for drafting the next point\n",
    "            squared_dist = np.min(distances, axis=1)**2\n",
    "            tot = np.sum(squared_dist)\n",
    "            prob = squared_dist / tot\n",
    "            self.centroids = np.vstack([self.centroids, X[rng.choice(n,1,p=prob)]])\n",
    "            count += 1        \n",
    "    \n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Fit the KMeans model to data X.\n",
    "        \"\"\"\n",
    "        # Nothing to be done here that isn't accounted for by other methods.\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict cluster labels for new data.\n",
    "        \"\"\"\n",
    "        distances = self.euclidean_distance_vectorized(X, self.centroids)\n",
    "        # Assign each data point to the cluster corresponding to its closest centroid\n",
    "        labels = np.argmin(distances, axis=1)\n",
    "        return labels\n",
    "    \n",
    "    def fit_predict(self, X):\n",
    "        \"\"\"\n",
    "        Perform KMeans clustering and return cluster labels.\n",
    "        \"\"\"\n",
    "        self.fit(X)\n",
    "        iter = 0\n",
    "        while (iter < self.max_iters):\n",
    "            iter += 1\n",
    "            self.labels_ = self.predict(X)\n",
    "            # Calculate the new centroid of the each class\n",
    "            new_centroids = np.empty((self.k, len(X[0])), dtype=float)\n",
    "            deltas = np.empty(self.k, dtype=float)\n",
    "            for i in range(self.k):\n",
    "                new_centroids[i] = np.mean(X[self.labels_ == i], axis = 0)\n",
    "                deltas[i] = np.sqrt(np.sum((self.centroids[i] - new_centroids[i])**2))\n",
    "            # Algorithm terminates if convergence condition is met\n",
    "            self.centroids = new_centroids\n",
    "            if np.max(deltas[i])<self.tol:\n",
    "                self.labels_ = self.predict(X)\n",
    "                break\n",
    "        if iter == self.max_iters:\n",
    "            print(\"Did not converge within\", self.max_iters, \"iterations!\")\n",
    "        else:\n",
    "            print(\"Converged after\", iter, \"iterations!\")\n",
    "        # Calculate average within-cluster variance\n",
    "        distances = self.euclidean_distance_vectorized(X, self.centroids)\n",
    "        # Return the loss function\n",
    "        return np.sum(np.min(distances, axis=1)) #self.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 21 iterations!\n",
      "Average within-cluster variance: 4144.1695069317175\n"
     ]
    }
   ],
   "source": [
    "# Generate some synthetic 2-dimensional data\n",
    "X = np.vstack((np.random.multivariate_normal((1,0), [[1, 0], [0, 4]], 1000),np.random.multivariate_normal((0,1), [[4, 0], [0, 1]], 1000),np.random.multivariate_normal((0,0), [[3, 1], [1, 3]], 1000)))\n",
    "true_labels = np.zeros(3000, dtype=int)\n",
    "true_labels[1000:2000] = 1\n",
    "true_labels[2000:3000] = 2\n",
    "\n",
    "# Run kMeans on the data\n",
    "KM = KMeans(k=3)\n",
    "KM.initialize_centroids(X)\n",
    "print(\"Average within-cluster variance:\", KM.fit_predict(X))\n",
    "# Let's see how many points were grouped into each cluster.\n",
    "# for i in range(3):\n",
    "#     print(np.sum(predicted_labels == i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** We are sometimes getting a message that we are taking the square root of a negative number.  This part of the code was taken directly from Manuel's sample code.  We are assuming that it is just due to a rounding error, and it does not seem to prevent the algorithm from working correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. kMeans++ initialization\n",
    "\n",
    "* Implement the kMeans++ initialization method in the KMeans class. **(RESULT)**\n",
    "* Compare the convergence speed of kMeans with random initialization and kMeans++ initialization on your synthetic dataset from Part 1. **(RESULT)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 14 iterations!\n",
      "Average within-cluster variance: 4144.509747538965\n"
     ]
    }
   ],
   "source": [
    "# Run kMeans on the data after using the kMeans++ initialization function\n",
    "KM = KMeans(k=3)\n",
    "KM.initialize_centroids_plusplus(X)\n",
    "print(\"Average within-cluster variance:\", KM.fit_predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Report:** kMeans++ converged in one third fewer steps in this case!  Usually it appears to be a smaller fraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Visualization of Cluster Quality\n",
    "\n",
    "\n",
    "* Visualize the clustering results of your kMeans implementation on a synthetic 2D dataset with at least 4 clusters using matplotlib. **(RESULT)**\n",
    "* Determine the optimal number of clusters using the elbow method. Report on your findings using a simple plot. **(RESULT)**\n",
    "* Report on the silhouette score of your clustering results for the optimal k and k-1. **(RESULT)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 20 iterations!\n",
      "6890.698072930838\n",
      "Converged after 31 iterations!\n",
      "5745.982522917386\n",
      "Converged after 12 iterations!\n",
      "5146.890266932354\n",
      "Converged after 35 iterations!\n",
      "4658.567370323681\n",
      "Converged after 15 iterations!\n",
      "4340.256228795284\n",
      "Converged after 29 iterations!\n",
      "4059.8808147582176\n",
      "Converged after 24 iterations!\n",
      "3840.0227384784052\n",
      "Converged after 38 iterations!\n",
      "3616.2239142140434\n",
      "Converged after 29 iterations!\n",
      "3492.6520943293954\n",
      "Converged after 27 iterations!\n",
      "3371.470595330731\n",
      "Converged after 21 iterations!\n",
      "3230.191206146854\n",
      "Converged after 14 iterations!\n",
      "3158.8602546085312\n",
      "Converged after 79 iterations!\n",
      "2960.1873149493267\n",
      "Converged after 30 iterations!\n",
      "2880.9839572956193\n",
      "Converged after 18 iterations!\n",
      "2828.586863498779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/qy3hxmtx741d5d_h4sl68nt00000gn/T/ipykernel_72672/1255888261.py:44: RuntimeWarning: invalid value encountered in sqrt\n",
      "  distances = np.sqrt(X_1_sqnorms + X_2_sqnorms - 2 * dots)  # X_1_sqnorms + X_2_sqnorms - broadcasted addition (n_1, n_2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 16 iterations!\n",
      "2785.52768519988\n",
      "Converged after 20 iterations!\n",
      "2679.930873201686\n",
      "Converged after 11 iterations!\n",
      "2631.1975828727936\n",
      "Converged after 46 iterations!\n",
      "2549.4899734319806\n",
      "Converged after 40 iterations!\n",
      "2485.845655359998\n",
      "Converged after 12 iterations!\n",
      "2454.7358122934866\n",
      "Converged after 6 iterations!\n",
      "2459.127914843383\n",
      "Converged after 40 iterations!\n",
      "2318.75301695335\n",
      "Converged after 21 iterations!\n",
      "2361.212229895458\n",
      "Converged after 13 iterations!\n",
      "2289.8318704680323\n",
      "Converged after 28 iterations!\n",
      "2273.9667619347365\n",
      "Converged after 5 iterations!\n",
      "2275.0011352447973\n",
      "Converged after 5 iterations!\n",
      "2189.8602809692816\n",
      "Converged after 13 iterations!\n",
      "2129.153214055662\n",
      "Converged after 14 iterations!\n",
      "2105.995310442894\n"
     ]
    }
   ],
   "source": [
    "# Generate some synthetic 2-dimensional data\n",
    "X = np.vstack((np.random.multivariate_normal((1,0), [[1, 0], [0, 4]], 1000),np.random.multivariate_normal((0,1), [[4, 0], [0, 1]], 1000),np.random.multivariate_normal((0,0), [[3, 1], [1, 3]], 1000),np.random.multivariate_normal((1,1), [[3, 1], [1, 3]], 1000)))\n",
    "\n",
    "for k in range(30):\n",
    "    KM = KMeans(k+2)\n",
    "    KM.initialize_centroids_plusplus(X)\n",
    "    print(KM.fit_predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.1.2 - DBSCAN (BONUS)\n",
    "\n",
    "DBSCAN is a density-based clustering algorithm that groups together points that are closely packed together, marking outliers points that lie alone in low-density regions.\n",
    "\n",
    "* Implement the DBSCAN algorithm using `numpy` only. Use the `DBSCAN` class structure below. **(RESULT)**\n",
    "* Test your DBSCAN implementation on a synthetic 2D dataset with noise. Visualize the clustering results using matplotlib. **(RESULT)**\n",
    "* Compare the performance of your DBSCAN implementation with your kMeans implementation on the same synthetic 2D dataset using silhouette score as a metric. Please use the same random seed to make it comparable. **(RESULT)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque   # Useful for efficient BFS implementation (FIFO) for iterating through neighboring points\n",
    "\n",
    "class DBSCAN:\n",
    "    def __init__(self, eps=0.5, min_samples=5, metric='euclidean'):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        eps : float\n",
    "            Maximum distance between two samples for them to be considered neighbors\n",
    "        min_samples : int\n",
    "            Number of samples in a neighborhood for a point to be considered a core point\n",
    "            (including the point itself)\n",
    "        metric : str\n",
    "            Distance metric to use ('euclidean' or 'manhattan')\n",
    "        \"\"\"\n",
    "        self.eps = eps\n",
    "        self.min_samples = min_samples\n",
    "        self.metric = metric\n",
    "        self.labels_ = None\n",
    "        self.core_sample_indices_ = None\n",
    "        self.components_ = None\n",
    "        self.n_clusters_ = None\n",
    "        self.n_noise_ = None\n",
    "    \n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Perform DBSCAN clustering.\n",
    "        \"\"\"\n",
    "        # TODO: Implement this function\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X_new):\n",
    "        \"\"\"\n",
    "        Predict the closest cluster for new points.\n",
    "        Note: New points can only be assigned to existing clusters or marked as noise.\n",
    "        \"\"\"\n",
    "        # TODO: Implement this function\n",
    "        pass\n",
    "    \n",
    "    def fit_predict(self, X):\n",
    "        \"\"\"\n",
    "        Perform DBSCAN clustering and return cluster labels.\n",
    "        \n",
    "        \"\"\"\n",
    "        self.fit(X)\n",
    "        return self.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Congratz, you made it! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
