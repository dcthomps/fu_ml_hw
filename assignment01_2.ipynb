{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1.2 - KNNR / DNNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course Assignment Guidelines\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Weekly Assignment Structure\n",
    "\n",
    "Each week includes **two assignments**:\n",
    "\n",
    "| File Format | Required For |\n",
    "|-------------|--------------|\n",
    "| `assignment[x]_1.ipynb` | All students |\n",
    "| `assignment[x]_2.ipynb` | 10 ECTS students only |\n",
    "\n",
    "Upload your solution as a `.ipynb` file **AND** a `.pdf` file in the respective entry in the whiteboard. You will find each deadline there as well.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Grading Requirements\n",
    "\n",
    "### Pass/Fail System\n",
    "* Each submitted `.ipynb` notebook receives either a **\"pass\"** or **\"fail\"** grade\n",
    "* **Minimum # of passes: n-1** \n",
    "\n",
    "### Separate Tracking\n",
    "The n-1 # of passes is tracked **separately** for each assignment type:\n",
    "\n",
    "#### For 5 ECTS Students:\n",
    "- ‚úîÔ∏è Must achieve n-1 # of passes on `assignment[x]_1.ipynb` series\n",
    "\n",
    "#### For 10 ECTS Students:\n",
    "- ‚úîÔ∏è Must achieve n-1 # of passes on `assignment[x]_1.ipynb` series\n",
    "- ‚úîÔ∏è Must achieve n-1 # of passes on `assignment[x]_2.ipynb` series\n",
    "\n",
    "---\n",
    "\n",
    "## üåü BONUS Tasks\n",
    "\n",
    "- **Optional BONUS tasks** appear in some notebooks\n",
    "- Successfully completing **BONUS** tasks earns **extra points** toward your final grade\n",
    "- Check the **Whiteboard** assignment grading for bonus point confirmations\n",
    "- 10 ECTS students will find separate bonus tasks in `assignment[x]_2.ipynb`\n",
    "- 5 ECTS students will **NOT** get additional extra points for solving `assignment[x]_2.ipynb` Bonus tasks\n",
    "- Vice Versa: 10 ECTS students will **NOT** get additional extra points for solving `assignment[x]_1.ipynb` Bonus tasks\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Quick Summary\n",
    "\n",
    "| Study Program | Requirements | Pass Criteria |\n",
    "|---------------|-------------|---------------|\n",
    "| **5 ECTS** | `assignment[x]_1.ipynb` | n-1 |\n",
    "| **10 ECTS** | `assignment[x]_1.ipynb` + `assignment[x]_2.ipynb` | n-1 each |\n",
    "| **All Students** | Optional BONUS tasks | Extra final exam points |\n",
    "\n",
    "\n",
    "**Note:** The n-1 rule is mandatory to pass the tutorial component of the module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please submit your solution of this notebook in the Whiteboard at the corresponding Assignment entry as .ipynb-file and as .pdf. <br><br>\n",
    "Please do **NOT** rename the file!\n",
    "\n",
    "#### State both names of your group members here:\n",
    "[Jane and John Doe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daniel Thompson and Paola Gega"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading Info/Details - Assignment 1.2:\n",
    "\n",
    "The assignment will be graded semi-automatically, which means that your code will be tested against a set of predefined test cases and qualitatively assessed by a human. This will speed up the grading process for us.\n",
    "\n",
    "* For passing the test scripts: \n",
    "    - Please make sure to **NOT** alter predefined class or function names, as this would lead to failing of the test scripts.\n",
    "    - Please do **NOT** rename the files before uploading to the Whiteboard!\n",
    "\n",
    "* **(RESULT)** tags indicate checkpoints that will be specifically assessed by a human.\n",
    "\n",
    "* You will pass the assignment if you pass the majority of test cases and we can at least confirm effort regarding the **(RESULT)**-tagged checkpoints per task.\n",
    "\n",
    "Note: For now, we will keep the test cases black-boxed, meaning we won't reveal their internal implementation details. This might be subject to change in the future, depending on how well we can keep up writing test cases for upcoming assignments which are still work in progress. (:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.2.1 - kNN on House Pricing Data (KNNR)\n",
    "\n",
    "Implement the k-Nearest Neighbor (kNN) algorithm from scratch using only NumPy. <br><br> You may use the provided sklearn functions to load datasets and evaluate your results. Apply your kNN implementation on a regression Problem - the [California Housing Dataset](https://www.kaggle.com/datasets/camnugent/california-housing-prices).\n",
    "\n",
    "* Show 5 data samples to get an idea of the data. **(RESULT)**\n",
    "* Split the dataset into a training set (80%) and a test set (20%). Train your model on the training set and evaluate it on the test set using the mean squared error (MSE) as a metric. Try at least 3 different values for k (e.g., 1, 3, 5) and 2 different distance measures (e.g., Euclidean, Manhattan). Report on your results. **(RESULT)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAGwCAYAAABFFQqPAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAOuJJREFUeJzt3QmcjXX///HPGMxYR4MxIxODsu9ZRooiW4WbSloskWhBqOguojSEkhJtiIjIUirFZIks2bKEwog0QyVjyTpz/R+f7/075z9nzBlzNGfmnHO9no/Hdc9cyznne645t/PuuwZZlmUJAACADeXJ7QIAAADkFoIQAACwLYIQAACwLYIQAACwLYIQAACwLYIQAACwLYIQAACwrby5XQBfl5qaKr///rsUKVJEgoKCcrs4AAAgC3SaxFOnTknp0qUlTx739T4EoSvQEBQdHZ2Vew4AAHzM4cOHpUyZMm7PE4SuQGuCHDeyaNGi2fvXAQAAXnHy5ElTkeH4HneHIHQFjuYwDUEEIQAA/MuVurXQWRoAANgWQQgAANiW3wShuLg4qV+/vmnri4iIkA4dOsjevXuv+Lh58+ZJ5cqVJTQ0VGrUqCFffvlljpQXAAD4Pr8JQqtWrZLHH39c1q9fL8uWLZOLFy9Ky5Yt5cyZM24f8/3330uXLl2kZ8+esnXrVhOedNu5c2eOlh0AAPimIEsH2vuhP/74w9QMaUC65ZZbMrymc+fOJigtWbLEeaxRo0ZSu3ZtmTJlSpZ7nYeFhUlycjKdpQEA8BNZ/f72mxqh9PSNqfDwcLfXrFu3Tlq0aOFyrFWrVua4O+fPnzc3L+0GAAACUx5/ne15wIABctNNN0n16tXdXpeUlCSlSpVyOab7ejyzvkiaIB0bkykCABC4/DIIaV8h7eczZ86cbH/uoUOHmtomx6YTKQIAgMDkdxMqPvHEE6bPz+rVqzOdMltFRkbK0aNHXY7pvh53JyQkxGwAACDw+U2NkPbp1hC0cOFC+fbbbyUmJuaKj4mNjZX4+HiXYzriTI8DAIDck5Jqybr9f8nibUfMT93PDXn9qTls9uzZsnjxYjOXkKOfj/bjKVCggPm9a9eucu2115p+Pqp///7StGlTGT9+vNxxxx2mKW3Tpk3y7rvv5up7AQDAzpbuTJQRn/8kicnnnMeiwkJl+F1VpXX1qBwti9/UCE2ePNn02WnWrJlERUU5t7lz5zqvOXTokCQmJjr3GzdubMKTBp9atWrJ/PnzZdGiRZl2sAYAAN4NQX0/2uISglRS8jlzXM/nJL+dRyinMI8QAADZQ5u/moz59rIQ5KDLo0aGhcqaZ2+T4DyZL5Yqdp9HCAAA+JeNCcfdhiClNTN6Xq/LKQQhAACQI46dOpet12UHghAAAMgREUVCs/W67EAQAgAAOaJBTLgZHeau948e1/N6XU4hCAEAgByhHaB1iLxKH4Yc+3r+33aU9gRBCAAA5BidJ2jyg3XN6LC0dF+P5/Q8Qn4zoSIAAAgMratHye1VI83oMO0YrX2CtDksJ2uCHAhCAAAgx2noia1QXHIbTWMAAMC2CEIAAMC2CEIAAMC2CEIAAMC2CEIAAMC2CEIAAMC2CEIAAMC2CEIAAMC2CEIAAMC2CEIAAMC2CEIAAMC2CEIAAMC2CEIAAMC2CEIAAMC2CEIAAMC2CEIAAMC2CEIAAMC2CEIAAMC2CEIAAMC2CEIAAMC2CEIAAMC2CEIAAMC2CEIAAMC2CEIAAMC2CEIAAMC2CEIAAMC2/CoIrV69Wu666y4pXbq0BAUFyaJFizK9fuXKlea69FtSUlKOlRkAAPguvwpCZ86ckVq1asmkSZM8etzevXslMTHRuUVERHitjAAAwH/kFT/Spk0bs3lKg0+xYsW8UiYAAOC//KpG6GrVrl1boqKi5Pbbb5e1a9dmeu358+fl5MmTLhsAAAhMAR2ENPxMmTJFPv30U7NFR0dLs2bNZMuWLW4fExcXJ2FhYc5NHwMAAAJTkGVZlvgh7fS8cOFC6dChg0ePa9q0qVx33XUyc+ZMtzVCujlojZCGoeTkZClatOi/LjcAAPA+/f7WCo0rfX/7VR+h7NCgQQNZs2aN2/MhISFmAwAAgS+gm8Yysm3bNtNkBgAA4Fc1QqdPn5Z9+/Y59xMSEkywCQ8PN81dQ4cOlSNHjsiMGTPM+QkTJkhMTIxUq1ZNzp07J++//758++238s033+TiuwAAAL7Cr4LQpk2b5NZbb3XuDxw40Pzs1q2bTJ8+3cwRdOjQIef5CxcuyKBBg0w4KliwoNSsWVOWL1/u8hwAAMC+/LaztK91tgIAAP73/W27PkIAAAAOBCEAAGBbBCEAAGBbBCEAAGBbBCEAAGBbBCEAAGBbBCEAAGBbBCEAAGBbBCEAAGBbBCEAAGBbBCEAAGBbBCEAAGBbBCEAAGBbBCEAAGBbBCEAAGBbBCEAAGBbBCEAAGBbBCEAAGBbBCEAAGBbBCEAAGBbBCEAAGBbBCEAAGBbBCEAAGBbBCEAAGBbBCEAAGBbBCEAAGBbHgehGTNmyPnz5y87fuHCBXMOAADAXwRZlmV58oDg4GBJTEyUiIgIl+N//fWXOZaSkiKB5OTJkxIWFibJyclStGjR3C4OAADIxu9vj2uENDcFBQVddvy3334zLwgAAOAv8mb1wjp16pgApFvz5s0lb97//1CtBUpISJDWrVt7q5wAAAC5F4Q6dOhgfm7btk1atWolhQsXdp7Lnz+/lCtXTjp16pT9JQQAAMjtIDR8+HDzUwNP586dJTQ01FtlAgAA8K0g5NCtWzfnKLFjx45Jamqqy/nrrrsu+0oHAADgS0Hol19+kYcffli+//77DDtRB9qoMQAAELg8HjXWvXt3yZMnjyxZskQ2b94sW7ZsMdvWrVvNT29avXq13HXXXVK6dGkTuhYtWnTFx6xcuVLq1q0rISEhUrFiRZk+fbpXywgAAAK4Rkg7S2sAqly5suS0M2fOSK1atUyNVMeOHa94vY5ku+OOO6RPnz4ya9YsiY+Pl169eklUVJTp8A0AAOzN4yBUtWpV+fPPPyU3tGnTxmxZNWXKFImJiZHx48eb/SpVqsiaNWvk9ddfJwgBAADPm8bGjBkjzzzzjGly0tmkdebGtJsvWbdunbRo0cLlmNYE6XF3dPkQX35PAAAgF2uEHMFCJ1X09c7SSUlJUqpUKZdjuq/h5uzZs1KgQIHLHhMXFycjRozIwVICAAC/CUIrVqyQQDZ06FAZOHCgc19DU3R0dK6WCQAA+EgQatq0qfiLyMhIOXr0qMsx3dfF1zKqDVI6ukw3AAAQ+DzuI6S+++47efDBB6Vx48Zy5MgRc2zmzJmmI7IviY2NNSPF0lq2bJk5DgAA4HEQ+vTTT02HY61R0XmDtHOx0mXuX3nlFa/e0dOnT5vh+7o5hsfr74cOHXI2a3Xt2tV5vQ6bP3DggOncvWfPHnn77bflk08+kaeeesqr5QQAAAEahF5++WUzLP29996TfPnyOY/fdNNNXp9QcdOmTVKnTh2zKe3Lo78PGzbM7CcmJjpDkdKh81988YWpBdL5h3QY/fvvv8/QeQAAYARZOtzLAwULFpSffvrJLL5apEgR+fHHH6V8+fKm5kXnGDp37pwEEu0sHRYWZmq8tG8RAAAInO/vPFfTAXnfvn2XHdf+QRqIAAAA/IXHQeiRRx6R/v37y4YNG8y8Qb///rtZvmLw4MHSt29f75QSAADAF4bPDxkyRFJTU82Eiv/884/ccsstZri5BqEnn3zSG2UEAADwjT5CDhcuXDBNZDqSS/sGFS5cWAIRfYQAAAjc72+Pa4Qc8ufPbwIQAACAv/I4CJ05c0ZGjx5tJio8duyYaSZLS0ePAQAABGQQ6tWrl6xatUoeeughiYqKMh2mAQAAbBGEvvrqKzNJoU6gCAAAYKvh89dcc42Eh4d7pzQAAAC+HIReeukls6SFDp0HAACwVdOYrte1f/9+KVWqlFlmI+16Y8rb640BAADkWhDq0KFDtr04AACAX06oaBdMqAgAgP/x+oSKmzdvlt27d5vfq1WrJnXq1LnapwIAAMgVHgchnUTxvvvuk5UrV0qxYsXMsRMnTsitt94qc+bMkZIlS3qjnAAAALk/akwXVj116pTs2rVLjh8/bradO3eaKqh+/fplfwkBAAB8pY+QtrctX75c6tev73J848aN0rJlS1M7FEjoIwQAQOB+f3tcI6Rri6UfMq/0WPp1xwAAAHyZx0Hotttuk/79+8vvv//uPHbkyBF56qmnpHnz5tldPgAAAN8JQm+99ZapbtLJFCtUqGC2mJgYc+zNN9/0TikBAAB8YdRYdHS0mT1a+wnt2bPHHKtSpYq0aNHCG+UDAPihlFRLNiYcl2OnzklEkVBpEBMuwXmCcrtYwGWYUPEK6CwNAJ5ZujNRRnz+kyQmn3MeiwoLleF3VZXW1aO4nfDvztIqPj5e7rzzTmfTmP6uNUQAAHvTENT3oy0uIUglJZ8zx/U84Es8DkJvv/22tG7dWooUKWI6TeumSatt27YyadIk75QSAOAXzWFaE5TRnCyOY3perwP8tmmsTJkyMmTIEHniiSdcjmsIeuWVV8wIskBC0xgAZM26/X9Jl/fWX/G6jx9pJLEVinNb4Z9NYzphotYIpaeTKeqLAQDsSTtGZ+d1QE7wOAi1a9dOFi5ceNnxxYsXm75CAAB70tFh2Xkd4JPD56tWrSqjRo0yi67GxsaaY+vXr5e1a9fKoEGDZOLEic5rWXsMAOxDh8jr6DDtGJ1RnwsdPB8Z9r+h9IDf9hHSyROz9MRBQXLgwAHxd/QRAgDPR42ptF8ujhmEJj9YlyH08Knvb49rhBISEv5t2QAAAUrnCdKwk34eIa0JYh4h+CKPgxAAAFcKQ7dXjWRmaQRmENKWtPnz58uKFSvk2LFjl604v2DBguwsHwDAD+lyGgyRR0AGoQEDBsg777wjt956q5QqVcr0BQIAALBFEJo5c6ap9dGZpAEAAGw1j5D2wC5fvrzkFp3Buly5chIaGioNGzaUjRs3ur12+vTppsYq7aaPAwAAuKog9OKLL8qIESPk7NmzOX4H586dKwMHDpThw4fLli1bpFatWtKqVSvTV8kdHTKXmJjo3H799dccLTMAAAigprF7771XPv74Y4mIiDA1M/ny5XM5rwHFW1577TV55JFHpEePHmZ/ypQp8sUXX8jUqVPN+mcZ0VqgyMhIr5UJAADYKAh169ZNNm/eLA8++GCOdpa+cOGCed2hQ4c6j+XJk0datGgh69atc/u406dPS9myZc3otrp165qFYatVq+b2+vPnz5st7YRMAAAgMHkchLQG5uuvv5YmTZpITvrzzz8lJSXFhK+0dH/Pnj0ZPqZSpUqmtqhmzZpmZslx48ZJ48aNZdeuXVKmTJkMHxMXF2ea/gAAQODzuI9QdHR0plNV+xJdC61r165Su3Ztadq0qRntVrJkSTP83x2tcdLQ5NgOHz6co2UGAAA+HITGjx8vzzzzjBw8eFByUokSJSQ4OFiOHj3qclz3s9oHSPsz1alTR/bt2+f2mpCQEBP00m4AACAweRyEtG+QzipdoUIFKVKkiISHh7ts3pI/f36pV6+exMfHO49pvx/d15qfrNCmtR07dkhUVJTXygkAAAK4j9CECRMkt+jQee2sfeONN0qDBg1MWc6cOeMcRabNYNdee63p56NGjhwpjRo1kooVK8qJEydk7NixZvh8r169cu09AAAAPx81lls6d+4sf/zxhwwbNkySkpJM35+lS5c6O1AfOnTIjCRz+Pvvv81we732mmuuMTVK33//vVStWjXX3gMAAPAdQZauouohbWJatGiR7N692+zrcPR27dqZPjyBRofP62za2nGa/kIAAATW97fHNULa0VjXGTty5IgZnq60KUpHk+nQeu07BAAAEJCdpfv162fCjg4r11mkddMmqZiYGHMOAADAX3hcI7Rq1SpZv369ywix4sWLy+jRo+Wmm27K7vIBAAD4To2QzrNz6tSpDJey0CHuAAAAARuE7rzzTundu7ds2LBBtJ+1blpD1KdPH9NhGgAAIGCD0MSJE00fIZ3EMDQ01GzaJKZz9bzxxhveKSUAAIAv9BEqVqyYLF682Iwecwyfr1KliglCAAAAARuEdEx+4cKFzaSFGnwc4UeXutBzzLMDAAACsmls4cKFZmmLc+fOXXbu7NmzUr9+ffn888+zu3wAAAC5H4QmT55sVp0vWLDgZecKFSokzz77rLz11lvZXT4AAIDcD0I7d+6UZs2auT1/yy23mJXdAQAAAi4I6QKmly5dcnv+4sWL5hoAAICAC0LlypWTTZs2uT2v58qWLZtd5QIAAPCdINSxY0f573//K0ePHr3sXFJSkjz//PPSqVOn7C4fAACA1wRZOjV0FuiyGjqJoi6w+uCDDzpXnt+zZ4/MmjXLrD6vM0wXKVJEAolOCxAWFibJyclMDwAAQIB9f2d5HiENOGvXrpWhQ4fK3Llznf2BdIJFDUajRo0KuBAEAAACW5ZrhNLSh/z555/mZ8mSJSUoKEgCFTVCAAD4n2yvEUpLg48GIAAAAFstugoAABAoCEIAAMC2CEIAAMC2CEIAAMC2stRZeuLEiVl+wn79+v2b8gAAAPjW8PmYmJisPVlQkBw4cEACCcPnAQCw+fD5hISE7CwbAACAT6CPEAAAsK2rmlDxt99+k88++8ysO3bhwgWXc6+99lp2lQ0AAMC3glB8fLy0a9dOypcvbxZcrV69uhw8eNAst1G3bl3vlBIAgFySkmrJxoTjcuzUOYkoEioNYsIlOE/gLi1lNx4HIV10dfDgwTJixAizyOqnn34qERER8sADD0jr1q29U0oAAHLB0p2JMuLznyQx+ZzzWFRYqAy/q6q0rh7F38SOfYR2794tXbt2Nb/nzZtXzp49K4ULF5aRI0fKmDFjvFFGAAByJQT1/WiLSwhSScnnzHE9DxsGoUKFCjn7BUVFRcn+/fud53RFegAAAqE5TGuCMppfxnFMz+t1sFnTWKNGjWTNmjVSpUoVadu2rQwaNEh27NghCxYsMOcAAPB32icofU1QWhp/9LxeF1uheI6WDbkchHRU2OnTp83v2k9If587d65cf/31jBgDAAQE7RidndchgIKQjhZL20w2ZcqU7C4TAAC5SkeHZed1CMAJFTdt2iQzZ8402+bNmyWnTJo0ScqVKyehoaHSsGFD2bhxY6bXz5s3TypXrmyur1Gjhnz55Zc5VlYAgH/SIfI6OszdIHk9ruf1OtgsCOlkijfffLM0aNBA+vfvb7b69etLkyZNzDlv0ia4gQMHyvDhw2XLli1Sq1YtadWqlRw7dizD67///nvp0qWL9OzZU7Zu3SodOnQw286dO71aTgCAf9N5gnSIvEofhhz7ep75hGyy6GpaOlfQiRMn5MMPP5RKlSqZY3v37pUePXqYRc2WLl3qrbKaGiANXW+99ZbZT01NlejoaHnyySdlyJAhl13fuXNnOXPmjCxZssR5TDt0165dO8tNeiy6CgD2xTxC/itbF11Na9WqVaamxRGClP7+5ptvmpoib9Eh+9oEpxM6OuTJk0datGgh69aty/AxelxrkNLSGqRFixa5fZ3z58+bLe2NBADYk06aeHvVSGaWDmAeByGtgbl48eJlx1NSUqR06dLiLTpHkb5GqVKlXI7rvi71kZGkpKQMr9fj7sTFxZnRcAAAKG3+Yoh84PK4j9DYsWNNU5R2lnbQ37Wv0Lhx48TfaY2TVqM5tsOHD+d2kQAAgK/UCHXv3l3++ecf019Hl9hQly5dMr8//PDDZnM4fvx4thW0RIkSEhwcLEePHnU5rvuRkZEZPkaPe3K9CgkJMRsAAAh8HgehCRMmSG7Inz+/1KtXT+Lj483IL0dnad1/4oknMnxMbGysOT9gwADnsWXLlpnjAAAAHgehbt265dpd047P+vo33nijGb6voUxHhemINaWLwV577bWmn4/S5rqmTZvK+PHj5Y477pA5c+aYZrx33303194DAADwsyCkI6ccQ8+uNIoqsyFq/5YOh//jjz9k2LBhpsOzDoPX4fqODtGHDh0yI8kcGjduLLNnz5bnn39ennvuObMMiI4Yq169utfKCAAAAmweIe2bk5iYKBERESZoBAVdPtemPo0e15FdgYR5hAAAsPk8Qt9++62Eh/9vGvEVK1ZkXykBAAD8aWZpu6FGCACAwP3+9ngeoWnTppmFTNPTY7rsBgAAgL/wOAjpiCyd0yc97T/0yiuvZFe5AAAAfC8I6cismJiYy46XLVvWnAMAAAjYIKQ1P9u3b7/s+I8//ijFixfPrnIBAAD4XhDq0qWL9OvXz4we06HyuumoMp288L777vNOKQEAAHxhZumXXnpJDh48KM2bN3euNaZLXeiszvQRAgAAthg+//PPP5vmsAIFCkiNGjVMH6FAxPB5AABsPqFiRm644QazAQAA+CuPg5D2CZo+fbpZ1f3YsWOmWSwt7S8EAAAQkEFIO0VrENLV3HXx0ozWHQMAAAjIIDRnzhz55JNPpG3btt4pEQAAgK8On8+fP79UrFjRO6UBAADw5SA0aNAgeeONN4S1WgEAgO2axtasWWMmU/zqq6+kWrVqki9fPpfzCxYsyM7yAQAA+E4QKlasmPznP//xTmkAAAB8OQhNmzbNOyUBAADw9T5CAAAAtqoRqlu3rplA8ZprrpE6depkOnfQli1bsrN8AAAAuRuE2rdvLyEhIeb3Dh06eK80AAAAvrroqi6vsXbtWqlZs6bpNG0HLLoKAEDgfn971EcoODhYWrZsKX///Xd2lBEAAMC/Okvr+mIHDhzwTmkAAAB8OQi9/PLLMnjwYFmyZIkkJiaaqqe0GwAA8H0pqZas2/+XLN52xPzUfTvyqI+QypPn/2entKPH9Gl0X/sRBRL6CAEAAs3SnYky4vOfJDH5nPNYVFioDL+rqrSuHiV2+v72eEJFXV4DAAD4bwjq+9EWSV8LkpR8zhyf/GDdgAlDWeFRENJan9KlS8uFCxekUqVKkjevxzkKAADkEm3+0pqgjJqCLG3pETHnb68aKcF53M8ZaMs+QgkJCWbYfOXKlc3PChUqyKZNm7xbOgAAkG02Jhx3aQ7LKAzpeb3OLrIchJ5++mm5dOmSfPTRRzJ//nwpU6aMPProo94tHQAAyDbHTp3L1usCQZbbttasWWMCUJMmTcx+o0aNTBg6c+aMFCpUyJtlBAAA2SCiSGi2XmerGqFjx47J9ddf79yPioqSAgUKmOMAAMD3NYgJN6PD3PX+Cfq/0WN6nV1kOQjp0PjTp0+7zBmkQ+lPnTrFPEIAAPgB7QCtQ+RV+jAU9H8/9bxdOkp7NI+Qhp70q8475g5K+zvzCAEA4NuYR+gq+ggxfxAAAIFB5wnSIfIbE46bjtHaJ0ibw+xUE+RxEGratKnkpuPHj8uTTz4pn3/+uamd6tSpk7zxxhtSuHBht49p1qyZrFq1yuWYjnSbMmVKDpQYAADfpaEntkJxsTu/mRHxgQceMGubLVu2TC5evCg9evSQ3r17y+zZszN93COPPCIjR4507hcsWDAHSgsAAPyBXwSh3bt3y9KlS+WHH36QG2+80Rx78803pW3btjJu3Dgz27U7GnwiIyOz/Frnz583mwMLyQIAELg8Xn0+N6xbt06KFSvmDEGqRYsWpolsw4YNmT521qxZUqJECalevboMHTpU/vnnn0yvj4uLM4u0Obbo6Ohsex8AAMC3+EWNUFJSkkRERLgc03XOwsPDzTl37r//filbtqypMdq+fbs8++yzsnfvXlmwYIHbx2hYGjhwoEuNEGEIAIDAlKtBaMiQITJmzJgrNotdLe1D5FCjRg0zCWTz5s1l//79Zq20jISEhJgNAAAEviwFoY4dO2b5CTOrbUlv0KBB0r1790yvKV++vOnjk34Ga133TEeSedL/p2HDhubnvn373AYhAABgH1kKQtpXxkEnTly4cKE55uizs3nzZjlx4oRHgUmVLFnSbFcSGxtrnl9fp169eubYt99+K6mpqc5wkxXbtm0zP7VmCAAAIMszSztoPxutidG5eIKDg80xnU36sccek6JFi8rYsWO9clfbtGkjR48eNa/rGD6vQcwxfP7IkSOm2WvGjBnSoEED0/yl53RkWfHixU0foaeeesosFJt+bqHMaB8hDX3Jycnm/QEAAN+X1e9vj0eNTZ06VQYPHuwMQUp/1w7Ges5bdPRX5cqVTdjRcNOkSRN59913nec1HGlHaMeosPz588vy5culZcuW5nHaDKeTMOqEjAAAAFfVWVr75uzZs0cqVarkclyPaVOVt+gIscwmTyxXrpxptnPQkV6e1PwAAAD78TgIaZNUz549TdOTNkEpnctn9OjR5hwAAEDABiGdyVlHao0fP94seeHofPz000+b5icAAICA7SydlmP5iUDuRExnaQAAAvf7+19NqBjIAQgAAAQ+j0eN6RD2hx56yCxboctc6IixtBsAAIC/8LhGSGeCPnTokLzwwgumb1BQUJB3SgYAAOBrQWjNmjXy3XffSe3atb1TIgAAAF9tGtP5ef5F/2oAAAD/DUITJkwwq8YfPHjQOyUCAADw1aaxzp07m2UsdPX2ggULSr58+VzO6zpkAAAAARmEtEYIAADAlkGoW7du3ikJAABADruqCRVTUlJk0aJFsnv3brNfrVo1adeuHfMIAQCAwA5C+/btk7Zt28qRI0ecK9DHxcWZ0WRffPGF6TsEAAAQkKPG+vXrZ8LO4cOHZcuWLWbTCRZjYmLMOQAAgICtEVq1apWsX79ewsPDnceKFy8uo0ePlptuuim7ywcAAOA7NUIhISFy6tSpy46fPn1a8ufPn13lAgAA8L0gdOedd0rv3r1lw4YNZoZp3bSGqE+fPqbDNAAAQMAGoYkTJ5o+QrGxsRIaGmo2bRKrWLGivPHGG94pJQAAgC/0ESpWrJgsXrzYjB5zDJ+vUqWKCUIAAAABP4+Q0uBD+AEAALZqGuvUqZOMGTPmsuOvvvqq3HPPPdlVLgAAAN8LQqtXrzYTKqbXpk0bcw4AACBgg5C7YfK6Cv3Jkyezq1wAAAC+F4Rq1Kghc+fOvez4nDlzpGrVqtlVLgAAAN/rLP3CCy9Ix44dZf/+/XLbbbeZY/Hx8fLxxx/LvHnzvFFGAAAA3whCd911l1l5/pVXXpH58+dLgQIFpGbNmrJ8+XJp2rSpd0oJAADgBUGWTg0Nt7TfU1hYmCQnJ0vRokW5UwAABND3t8d9hNSJEyfk/fffl+eee06OHz9ujukq9EeOHLn6EgMAAPh609j27dulRYsWJmUdPHhQevXqZVaiX7BggRw6dEhmzJjhnZICAABkM49rhAYOHCjdu3eXX375xawz5qBzCzGPEAAACOgg9MMPP8ijjz562fFrr71WkpKSsqtcAAAAvheEQkJCMpw48eeff5aSJUtmV7kAAAB8Lwi1a9dORo4cKRcvXjT7QUFBpm/Qs88+a9YhAwAACNggNH78eLPMRkREhJw9e9bMHaSr0BcpUkRGjRrlnVKKmOdu3LixFCxYUIoVK5alx+jMAMOGDZOoqCgz35F28ta+TQAAAFc1akxHiy1btkzWrl0rP/74owlFdevWNSHDmy5cuGBWt4+NjZUPPvggS4959dVXZeLEifLhhx9KTEyMmRW7VatW8tNPP7l09AYAAPbkdxMqTp8+XQYMGGDmMsqMvq3SpUvLoEGDZPDgweaYTqpUqlQp8xz33Xdfho87f/682Ry0P1R0dDQTKgIAYOcJFdetWydLlixxOaZzBmlNizaT9e7d2yVA5LaEhAQzii1tTZXekIYNG5r34k5cXJy5zrFpCAIAAIEpy0FIO0jv2rXLub9jxw7p2bOnCRpDhgyRzz//3IQIX+EYyq81QGnpfmbD/IcOHWrSo2M7fPiw18sKAAB8PAht27ZNmjdv7tyfM2eOqV157733zCSL2hfnk08+8ejFNUDpqLPMtj179khO0ukBtAot7QYAAGzeWfrvv/92qV1ZtWqVtGnTxrlfv359j2tPtP+OzlKdmfLly8vViIyMND+PHj1qRo056H7t2rWv6jkBAIBNg5CGIO13o31mdASXLrI6YsQI5/lTp05Jvnz5PHpxnYDRW5Mwat8lDUPx8fHO4KMdpzZs2CB9+/b1ymsCAIAAbRrTtcS0Keu7774z/Wh0Pp+bb77ZZTHWChUqeKucZtJGbZ7TnykpKeZ33XT4vkPlypVl4cKF5ndtVtPRZS+//LJ89tlnpk9T165dzUiyDh06eK2cAAAgAGuEXnrpJenYsaOZQLFw4cJmbp78+fM7z0+dOlVatmzprXKaiRH1NR3q1Kljfq5YsUKaNWtmft+7d6/p4OzwzDPPyJkzZ8yINh1u36RJE1m6dClzCAEAgKubR0iDhgah4OBgl+PHjx83x9OGIzvNQwAAAPzv+/uqZpbOSHh4uKdPBQAA4F9rjQEAAAQKghAAALAtghAAALAtghAAALAtghAAALAtghAAALAtghAAALAtghAAALAtghAAALAtghAAALAtghAAALAtghAAALAtghAAALAtghAAALAtghAAALAtghAAALAtghAAALAtghAAALAtghAAALAtghAAALAtghAAALAtghAAALAtghAAALAtghAAALAtghAAALAtghAAALAtghAAALAtghAAALAtghAAALAtghAAALAtghAAALAtghAAALAtghAAALAtvwlCo0aNksaNG0vBggWlWLFiWXpM9+7dJSgoyGVr3bq118sKAAD8Q17xExcuXJB77rlHYmNj5YMPPsjy4zT4TJs2zbkfEhLipRICAAB/4zdBaMSIEebn9OnTPXqcBp/IyMgsX3/+/HmzOZw8edKj1wMAAP7Db5rGrtbKlSslIiJCKlWqJH379pW//vor0+vj4uIkLCzMuUVHR+dYWQEAQM4K6CCkzWIzZsyQ+Ph4GTNmjKxatUratGkjKSkpbh8zdOhQSU5Odm6HDx/O0TIDAACbNI0NGTLEBJTM7N69WypXrnxVz3/fffc5f69Ro4bUrFlTKlSoYGqJmjdv7rYpjX5EAADYQ64GoUGDBpmRXZkpX758tr2ePleJEiVk3759boMQAACwj1wNQiVLljRbTvntt99MH6GoqKgce00AAOC7/KaP0KFDh2Tbtm3mp/bx0d91O336tPMabUJbuHCh+V2PP/3007J+/Xo5ePCg6SfUvn17qVixorRq1SoX3wkAAPAVfjN8ftiwYfLhhx869+vUqWN+rlixQpo1a2Z+37t3r+ngrIKDg2X79u3mMSdOnJDSpUtLy5Yt5aWXXqIPEAAAMIIsy7K4F+7pPEI6jF4DVtGiRblVAAAE0Pe33zSNAQAAZDeCEAAAsC2CEAAAsC2CEAAAsC2CEAAAsC2CEAAAsC2CEAAAsC2CEAAAsC2CEAAAsC2CEAAAsC2CEAAAsC2CEAAAsC2CEAAAsC2CEAAAsC2CEAAAsC2CEAAAsK28uV0AO0pJtWRjwnE5duqcRBQJlQYx4RKcJyi3iwUAgO0QhHLY0p2JMuLznyQx+ZzzWFRYqAy/q6q0rh6V08UBAMDWaBrL4RDU96MtLiFIJSWfM8f1PAAAyDkEoRxsDtOaICuDc45jel6vAwAAOYMglEO0T1D6mqC0NP7oeb0OAADkDIJQDtGO0dl5HQAA+PcIQjlER4dl53UAAODfIwjlEB0ir6PD3A2S1+N6Xq8DAAA5gyCUQ3SeIB0ir9KHIce+nmc+IQAAcg5BKAfpPEGTH6wrkWGuzV+6r8eZRwgAgJzFhIo5TMPO7VUjmVkaAAAfQBDKBdr8FVuheG68NAAASIOmMQAAYFsEIQAAYFsEIQAAYFsEIQAAYFsEIQAAYFsEIQAAYFt+EYQOHjwoPXv2lJiYGClQoIBUqFBBhg8fLhcuXMj0cefOnZPHH39cihcvLoULF5ZOnTrJ0aNHc6zcAADAt/lFENqzZ4+kpqbKO++8I7t27ZLXX39dpkyZIs8991ymj3vqqafk888/l3nz5smqVavk999/l44dO+ZYuQEAgG8LsizLEj80duxYmTx5shw4cCDD88nJyVKyZEmZPXu23H333c5AVaVKFVm3bp00atQow8edP3/ebA4nT56U6Oho83xFixb10rsBAADZSb+/w8LCrvj97bczS+sbCw93v1L75s2b5eLFi9KiRQvnscqVK8t1112XaRCKi4uTESNGZHhDAQCAf3B8b1+pvscvg9C+ffvkzTfflHHjxrm9JikpSfLnzy/FihVzOV6qVClzzp2hQ4fKwIEDnftHjhyRqlWrmlohAADgX06dOmVqhnwyCA0ZMkTGjBmT6TW7d+82NTlpg0nr1q3lnnvukUceeSTbyxQSEmI2B+1kffjwYSlSpIgEBQWJP3I07+n7oHmP+x7o+Lxz3+2Gz3zGtCZIQ1Dp0qUlM7kahAYNGiTdu3fP9Jry5cs7f9fOzrfeeqs0btxY3n333UwfFxkZaUaVnThxwqVWSEeN6bmsypMnj5QpU0YCgYYgghD33S74vHPf7YbP/OUyqwnyiSCknZl1ywqtCdIQVK9ePZk2bZoJKJnR6/Llyyfx8fFm2Lzau3evHDp0SGJjY7Ol/AAAwL/5xfB5DUHNmjUzHZ21X9Aff/xh+vmk7euj12gT2saNG50pUOce0v4+K1asMJ2ne/ToYUKQu47SAADAXvyis/SyZctMB2nd0jdTOXqD6wgxrfH5559/nOd0viGtOdIaIR0S36pVK3n77bfFbrTPk05AmbbvE7jvgYrPO/fdbvjM23QeIQAAAFs0jQEAAHgDQQgAANgWQQgAANgWQQgAANgWQShAjRo1ykw8WbBgwcuWGXFH+80PGzZMoqKipECBAmadtl9++cXrZQ0kx48flwceeMBMbKb3XadwOH36dKaP0akhdNbytFufPn1yrMz+aNKkSVKuXDkJDQ2Vhg0bOqfNcGfevHlmeg29vkaNGvLll1/mWFntet+nT59+2edaHwfPrF69Wu666y4zO7Lew0WLFl3xMStXrpS6deua0WQVK1Y0fwu4RxAKUDqrti5D0rdv3yw/5tVXX5WJEyfKlClTZMOGDVKoUCEz5cC5c+e8WtZAoiFo165dZsqHJUuWmH/EevfufcXH6XIxiYmJzk3/FsjY3LlzzfxgOiXEli1bpFatWuZzeuzYsQyv//7776VLly4mlG7dulU6dOhgtp07d3KLvXjflf4HQdrP9a+//so999CZM2fMvdYQmhUJCQlyxx13mAmIt23bJgMGDJBevXrJ119/zb13R4fPI3BNmzbNCgsLu+J1qampVmRkpDV27FjnsRMnTlghISHWxx9/7OVSBoaffvpJp6KwfvjhB+exr776ygoKCrKOHDni9nFNmza1+vfvn0Ol9H8NGjSwHn/8ced+SkqKVbp0aSsuLi7D6++9917rjjvucDnWsGFD69FHH/V6We1837P6bw+yTv99WbhwYabXPPPMM1a1atVcjnXu3Nlq1aoVt9oNaoTg/K8Inalbm8McdHZurf5et24ddykL9D5pc9iNN97oPKb3Uyf11Bq2zMyaNUtKlCgh1atXl6FDh7pMDArXmk6dJT7t51Tvr+67+5zq8bTXK63J4HPt3fuutFm4bNmyZtHn9u3bm9pSeBef9wCdWRre51iupFSpUi7HdT/tUibI/B5GRES4HMubN6+Eh4dneg/vv/9+82WhfQC2b98uzz77rJklfcGCBdzudP78809JSUnJ8HO6Z88et38XPtc5f98rVaokU6dOlZo1a0pycrJZHkn7LWoYCpSFrH2Ru8+7rlB/9uxZ0/8TrqgR8iNDhgy5rPNh+s3dP0rw3fuufYi0hkI78WofoxkzZsjChQtl//79/Nngt3Rdx65du0rt2rWladOmJtjrItvvvPNObhcNcEGNkB8ZNGiQdO/ePdNrypcvf1XPHRkZaX4ePXrUjBpz0H39h8zOsnrf9R6m7zh66dIlM5LMcX+zQpsjla6tV6FChassdWDS5sPg4GDzuUxL993dYz3uyfXInvueXr58+aROnTrmcw3vcfd5147r1AZljCDkR/S/pnTzhpiYGPN/oPj4eGfw0apU7dviycgzO993/S/gEydOmL4U9erVM8e+/fZbSU1NdYabrNCRHiptIMX/5M+f39xb/ZzqyC+l91f3n3jiCbd/Fz2vo2ccdFSfHof37nt62rS2Y8cOadu2Lbfdi/RznX56CD7vV+CuFzX826+//mpt3brVGjFihFW4cGHzu26nTp1yXlOpUiVrwYIFzv3Ro0dbxYoVsxYvXmxt377dat++vRUTE2OdPXs2l96F/2ndurVVp04da8OGDdaaNWus66+/3urSpYvz/G+//Wbuu55X+/bts0aOHGlt2rTJSkhIMPe+fPny1i233JKL78K3zZkzx4xmnD59uhmp17t3b/O5TUpKMucfeugha8iQIc7r165da+XNm9caN26ctXv3bmv48OFWvnz5rB07duTiuwj8+67/9nz99dfW/v37rc2bN1v33XefFRoaau3atSsX34X/0X+zHf9+61f2a6+9Zn7Xf+OV3nO99w4HDhywChYsaD399NPm8z5p0iQrODjYWrp0aS6+C99GEApQ3bp1M/+nSb+tWLHCeY3u6xDXtEPoX3jhBatUqVLmH7zmzZtbe/fuzaV34J/++usvE3w0fBYtWtTq0aOHS/jUsJP273Do0CETesLDw809r1ixovkHLDk5ORffhe978803reuuu87Knz+/Gda9fv16l+kI9POf1ieffGLdcMMN5nodWvzFF1/kQqntdd8HDBjgvFb/TWnbtq21ZcuWXCq5/9J/KzL6t9xxr/Wn3vv0j6ldu7a59/ofVmn/ncflgvR/rlRrBAAAEIgYNQYAAGyLIAQAAGyLIAQAAGyLIAQAAGyLIAQAAGyLIAQAAGyLIAQAAGyLIAQAAGyLIAT4sWbNmrmsoeVrVq5cKUFBQWYNtuyiz7do0SLJTrqormMNLQD2QhACfJx+SeuXf/pNV/FesGCBvPTSSzkSLNK+dlhYmNx0001mUdnMNG7cWBITE8312UWfr02bNpLTdBL+d9991yygW7hwYSlWrJjceOONMmHCBPnnn39yvDx2Cr+ANxGEAD/QunVrEwDSbjExMRIeHi5FihRx+7gLFy5kazmmTZtmXnvt2rVSokQJufPOO+XAgQMZXnvx4kWzanlkZKT5Yswu+nwhISGS0x566CFT+9a+fXtZsWKFbNu2TV544QVZvHixfPPNNzleHgDZgyAE+AH94tcAkHYLDg6+rGmsXLlypoaoa9euUrRoUendu7cJQ0888YRERUVJaGiolC1bVuLi4pzXq//85z8mrDj23dFaEH3t6tWry+TJk+Xs2bOybNkyc04fr8fatWsnhQoVklGjRl1WOzB9+nTzHF9//bVUqVLF1Kw4Ql5aU6dOlWrVqpn3reXW8mdUg3Xw4EGzP2fOHFP7pO9Py7Zq1Srn9SkpKdKzZ08THAsUKCCVKlWSN954w6P7/8knn8isWbPk448/lueee07q169v7pWGIq0Vu/XWW811qampMnLkSClTpowpe+3atWXp0qXO53GUV5/v5ptvNuXR5/r555/lhx9+MDVMek+0xuuPP/64rOluxIgRUrJkSfO37dOnj0vQPX/+vPTr108iIiLMfWjSpIl5TgfH3yI+Pt68TsGCBc0927t3r8t71WBXt25d8xzly5c3r3np0iWX+//++++bz4w+x/XXXy+fffaZ8/057sU111xjrtWyAz4tg4VYAfgQXV26ffv2GZ7TVaf79+/v3C9btqxZ9X7cuHHWvn37zDZ27FgrOjraWr16tXXw4EHru+++s2bPnm2uP3bsmFnJWlenTkxMNPvu6HULFy507h8/ftwcmzhxovN8RESENXXqVGv//v3Wr7/+6lw5+++//zbX6Ovky5fPatGihfXDDz9YmzdvtqpUqWLdf//9zud9++23rdDQUGvChAnW3r17rY0bN1qvv/56huVISEgw+2XKlLHmz59v/fTTT1avXr2sIkWKWH/++ae55sKFC9awYcPM6x04cMD66KOPrIIFC1pz587N0j1W7dq1sypVqmRdyWuvvWbu/8cff2zt2bPHeuaZZ8z7/fnnn13KW7lyZWvp0qWmvI0aNbLq1atnNWvWzFqzZo1Zob1ixYpWnz59XMpXuHBhq3PnztbOnTutJUuWWCVLlrSee+455zX9+vWzSpcubX355ZfWrl27zGOuueYa66+//jLnHX+Lhg0bWitXrjTX3HzzzVbjxo2dz6GfES3/9OnTzd/wm2++scqVK2e9+OKLLvdf77d+hn755Rfzulo2fZ1Lly5Zn376qblG/3b6mTpx4sQV7xuQmwhCgI/TL7Tg4GCrUKFCzu3uu+92G4Q6dOjg8vgnn3zSuu2226zU1NQsBRx30l535swZ67HHHjPl+vHHH53nBwwY4PKYjIKQ7mtAc5g0aZJVqlQp575+mf/3v//NUjkcwWL06NHO8xcvXjRf1GPGjHH7HI8//rjVqVOnLAchDWsahq5Eyz5q1CiXY/Xr1zf3Km1533//fed5DU16LD4+3nksLi7OJXhp+cLDw819d5g8ebIJICkpKdbp06dN4Jo1a5bzvAZALc+rr77q8rdYvny585ovvvjCHDt79qzZb968ufXKK6+4lH/mzJlWVFSUc1+vf/755537+tp67Kuvvsrwbw74ury5XSMF4Mq0uUGbnRy06ckdbfZIS5smbr/9dtMkpM1Q2q+nZcuWV3Xbu3TpYprktElMm2g++OADqVmzptvXzog2p1SoUMG5r01fx44dM7/rz99//12aN2/uUbliY2Odv+fNm9eUY/fu3c5jkyZNMs1thw4dMmXXJiVttsqq/33/Z+7kyZOm7NqJPC3d//HHH12Opb1npUqVMj9r1KjhcsxxTxxq1apl7l3a93z69Gk5fPiwJCcnmz5ZaV87X7580qBBA5f7kP619d4rfa3rrrvOlFP7f2mzZtqmxXPnzpkO4Y7XT/sc+lnUprr05QX8BUEI8AP6ZVOxYsUsX5uW9vdISEiQr776SpYvXy733nuvtGjRQubPn+9xOV5//XXzWB0FpkHoSq+dEf2CTkv7kTiChvaZyW7af2jw4MEyfvx4Ex60c/nYsWNlw4YNWX6OG264Qfbs2ZNtZUp7DxwdydMf0/5G3pDRazteS4OV9gnq2LHjZY/TPkMZPYe3ywt4G52lARvQ/2Lv3LmzvPfeezJ37lz59NNP5fjx484vNf2v/qzQjtIayDIKQdlBQ4p2QtYOvZ5Yv36983ft2Lt582bTGVtpDYd2Cn7sscekTp06pvz79+/36Pnvv/9+06FZOxKnpyFOa2T0HpcuXdq8Xlq6X7VqVfm3tLZGa7PSvmftWB0dHW1q2HSEXtrX1hoi7SztyWtraNbO03qP0m958mTt60LLobL6mQJyGzVCQIB77bXXTBOIhgD9Mps3b54JNDp6SzmChzar6EgnHe2Tm1588UUzIkpHP+noqVOnTpkv+CeffNLtY7TpS0cvafjRWqu///5bHn74YXNOj8+YMcOMVNORYzNnzjQBQX/PKq1FW7hwoWkafP75503ToobBHTt2mNfTsumorqefflqGDx9ugok2vel0AzrMXkec/VvanKej3/T1dXSWvo6OptO/qdbE9e3b17y+TqmgzVyvvvqqac7Sx2TVsGHDTNOpPv7uu+82z60BbOfOnfLyyy9n6Tl0VKLWEC1ZskTatm1ravk0sAG+iiAEBDitZdEvxV9++cX079Hh2l9++aXzv/C1yWjgwIGmtujaa681X7K5qVu3bqZPigYMbdLS+Yr0Szkzo0ePNpuGDq290OHc+jj16KOPytatW02NmH5Ba5jR2iFtKswqfdzs2bPNhIra10j70GhfJA1ZOlVBq1atzHU6fF1rhwYNGmT6zGhtjJZFr/u3tN+UPs8tt9xihsrr+9DQmPYeaPOUznek4VH7SWn48yTY6vvQAKNTAIwZM8bUFlauXFl69eqV5efQz5A2rw0ZMkR69Ohh7o9OmwD4qiDtMZ3bhQCAq6GhTWt2NOh40vnZ32iHd52LKbuXFgFAHyEAAGBjdJYGAAC2RdMYAACwLWqEAACAbRGEAACAbRGEAACAbRGEAACAbRGEAACAbRGEAACAbRGEAACAbRGEAACA2NX/A0Qu1VB/jip3AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get California Housing Data\n",
    "data = fetch_california_housing()\n",
    "X, y = data.data, data.target\n",
    "# print(X.shape, y.shape)\n",
    "\n",
    "# Split data and normalize features\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n",
    "X_train = (X_train-X_train.mean(axis=0))/X_train.std(axis=0)\n",
    "X_test = (X_test-X_test.mean(axis=0))/X_test.std(axis=0)\n",
    "\n",
    "# Choose five random samples from the training set\n",
    "rand_inds = np.array(np.random.choice(len(y_train), 5, replace=False)) # generate 5 random indices\n",
    "# First project on the pricipal components\n",
    "cov_matrix = np.cov(X_train.T)\n",
    "values, vectors = np.linalg.eig(cov_matrix)\n",
    "sorted_indices = np.argsort(values)[::-1]\n",
    "values_sorted = values[sorted_indices]\n",
    "vectors_sorted = vectors[:,sorted_indices]\n",
    "pca_components = vectors_sorted[:, :2]\n",
    "projected_data = np.dot(X_train[rand_inds], pca_components)\n",
    "# Plot the projection\n",
    "plt.scatter(projected_data[:, 0], projected_data[:, 1])\n",
    "plt.xlabel('First Principal Component')\n",
    "plt.ylabel('Second Principal Component')\n",
    "plt.show()\n",
    "\n",
    "# Make sure epsilon in suitably small for our data\n",
    "ep = np.min(X.std(axis=0)) * 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNRegressor:\n",
    "    \"\"\"Your KNN Regressor implementation\"\"\"\n",
    "    def __init__(self, k=3, p=2):\n",
    "        self.k = k\n",
    "        self.p = p\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"Fit the model using the training data.\"\"\"\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"Predict label for multiple samples.\"\"\"\n",
    "        n_test = len(X_test)\n",
    "        y_test_hat = np.empty(n_test, dtype=float) # initialise predicted label array\n",
    "        \n",
    "        for i in np.arange(n_test): # go through test samples\n",
    "            dist = np.linalg.norm(self.X_train - X_test[i], ord=self.p, axis=1) # compute L_p distance of every training sample to test sample at hand\n",
    "            sorted_ind = np.argsort(dist)[:self.k] # indices of k closest neighbors\n",
    "            \"\"\"Take a distance-weighted average of nearest_lables\"\"\"\n",
    "            y_test_hat[i]= np.sum(self.y_train[sorted_ind] / (dist[sorted_ind]+ep))/np.sum(1/(dist[sorted_ind]+ep))\n",
    "\n",
    "        return y_test_hat\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean metric:\n",
      "Mean squared error for k=1: 0.7228652850537789\n",
      "Mean squared error for k=3: 0.4521572001740188\n",
      "Mean squared error for k=5: 0.40101213146116593\n",
      "Manhattan metric:\n",
      "Mean squared error for k=1: 0.6538336442920057\n",
      "Mean squared error for k=3: 0.42596012840510444\n",
      "Mean squared error for k=5: 0.38467642204266445\n"
     ]
    }
   ],
   "source": [
    "print(\"Euclidean metric:\")\n",
    "for k in [1,3,5]:\n",
    "    KNN = KNNRegressor(k)\n",
    "    KNN.fit(X_train, y_train)\n",
    "    y_test_hat = KNN.predict(X_test)\n",
    "    print(\"Mean squared error for k={}:\".format(k), np.mean((y_test_hat - y_test)**2))\n",
    "print(\"Manhattan metric:\")\n",
    "for k in [1,3,5]:\n",
    "    KNN = KNNRegressor(k,p=1)\n",
    "    KNN.fit(X_train, y_train)\n",
    "    y_test_hat = KNN.predict(X_test)\n",
    "    print(\"Mean squared error for k={}:\".format(k), np.mean((y_test_hat - y_test)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.2.2 - DNNR\n",
    "\n",
    "Implement the DNNR algorithm yourself and apply it to the same regression problem from Task 1.2.1. <br><br> You may use the provided sklearn functions to load datasets and evaluate your results. Apply your kNN implementation on a regression Problem - the [California Housing Dataset](https://www.kaggle.com/datasets/camnugent/california-housing-prices).\n",
    "\n",
    "* Split the dataset into a training set (80%) and a test set (20%). Train your model on the training set and evaluate it on the test set using the mean squared error (MSE) as a metric. Try at least 3 different values for k (e.g., 1, 3, 5) and report the results. **(RESULT)**\n",
    "* How does the predicition quality of DNNR compare to kNN? Discuss your results. **(RESULT)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNNRegressor:\n",
    "    \"\"\"DNNR - uses local gradients for Taylor approximation\"\"\"\n",
    "    def __init__(self, k=5, p=2, k_gradient=10):\n",
    "        self.k = k  # neighbors for prediction\n",
    "        self.p = p\n",
    "        self.k_gradient = k_gradient  # neighbors for gradient estimation\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"Fit the model using the training data.\"\"\"\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        n_train = len(X_train)\n",
    "        self.gamma_hat = np.empty((n_train,len(X_train[0])), dtype=float) # initialise array of gradients\n",
    "        for i in np.arange(n_train): # go through test samples\n",
    "            dist = np.linalg.norm(self.X_train - X_train[i], ord=self.p, axis=1) # compute L_p distance of every training sample to test sample at hand\n",
    "            sorted_ind = np.argsort(dist)[1:self.k_gradient+1] # indices of k_gradient closest neighbors\n",
    "            \"\"\"Estimate the gradient near sample based on the labels of neighboring points\"\"\"\n",
    "            regressors = X_train[sorted_ind] - X_train[i]\n",
    "            self.gamma_hat[i] = np.linalg.inv(np.dot(regressors.T, regressors)).dot(regressors.T).dot(y_train[sorted_ind]-y_train[i])\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"Predict label for multiple samples.\"\"\"\n",
    "        n_test = len(X_test)\n",
    "        y_test_hat = np.empty(n_test, dtype=float) # initialise predicted label array\n",
    "        \n",
    "        for i in np.arange(n_test): # go through test samples\n",
    "            dist = np.linalg.norm(self.X_train - X_test[i], ord=self.p, axis=1) # compute L_p distance of every training sample to test sample at hand\n",
    "            sorted_ind = np.argsort(dist)[:self.k] # indices of k closest neighbors\n",
    "            \"\"\"Take the average of the labels predicted for x\n",
    "             based on first-order approximations of the model near neighboring points\"\"\"\n",
    "            y_test_hat[i]= np.mean(self.y_train[sorted_ind] +np.dot(self.gamma_hat[sorted_ind],X_test[i]-self.X_train[sorted_ind]))\n",
    "\n",
    "        return y_test_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean metric:\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLinAlgError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m [\u001b[32m1\u001b[39m,\u001b[32m3\u001b[39m,\u001b[32m5\u001b[39m]:\n\u001b[32m      3\u001b[39m     DNN = DNNRegressor(k, k_gradient=\u001b[32m24\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43mDNN\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     y_test_hat = DNN.predict(X_test)\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMean squared error for k=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m.format(k), np.mean((y_test_hat - y_test)**\u001b[32m2\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mDNNRegressor.fit\u001b[39m\u001b[34m(self, X_train, y_train)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Estimate the gradient near sample based on the labels of neighboring points\"\"\"\u001b[39;00m\n\u001b[32m     18\u001b[39m regressors = X_train[sorted_ind] - X_train[i]\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28mself\u001b[39m.gamma_hat[i] = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregressors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregressors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m.dot(regressors.T).dot(y_train[sorted_ind]-y_train[i])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/numpy/linalg/_linalg.py:669\u001b[39m, in \u001b[36minv\u001b[39m\u001b[34m(a)\u001b[39m\n\u001b[32m    666\u001b[39m signature = \u001b[33m'\u001b[39m\u001b[33mD->D\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33md->d\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    667\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m errstate(call=_raise_linalgerror_singular, invalid=\u001b[33m'\u001b[39m\u001b[33mcall\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    668\u001b[39m               over=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m, divide=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m, under=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m669\u001b[39m     ainv = \u001b[43m_umath_linalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m=\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(ainv.astype(result_t, copy=\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/numpy/linalg/_linalg.py:163\u001b[39m, in \u001b[36m_raise_linalgerror_singular\u001b[39m\u001b[34m(err, flag)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[33m\"\u001b[39m\u001b[33mSingular matrix\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mLinAlgError\u001b[39m: Singular matrix"
     ]
    }
   ],
   "source": [
    "print(\"Euclidean metric:\")\n",
    "for k in [1,3,5]:\n",
    "    DNN = DNNRegressor(k, k_gradient=24)\n",
    "    DNN.fit(X_train, y_train)\n",
    "    y_test_hat = DNN.predict(X_test)\n",
    "    print(\"Mean squared error for k={}:\".format(k), np.mean((y_test_hat - y_test)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Congratz, you made it! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
