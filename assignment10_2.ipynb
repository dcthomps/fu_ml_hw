{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 10.2 - Vision Model\n",
    "\n",
    "Please submit your solution of this notebook in the Whiteboard at the corresponding Assignment entry as .ipynb-file and as .pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Please state both names of your group members here:\n",
    "Jane and John Doe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 10.2.1: Pre-trained VGG-11 for Image Classification\n",
    "\n",
    "First, we recommend using PyTorch for this assignment, a popular machine learning framework. Should be able to install it according to the official instructions on [pytorch.org](https://pytorch.org/).\n",
    "\n",
    "It might be useful to use [Google Colab](https://colab.research.google.com), too. Google offers some compute, so you are not stuck running your programs locally. You can even use GPUs and TPUs! For this assignment, your local machine should be enough, though. In Google Colab variables might get lost when your computer disconnects from the internet or the notebook runs idle for a while. \n",
    "\n",
    "Browse through the [pytorch tutorials ](https://pytorch.org/tutorials/), they often come as colab notebooks - go and execute some!\n",
    "\n",
    "* Initialize and import the VGG-11 model using PyTorch. Use it for classifying at least 20 CIFAR10 Images, without training it from scratch. **(RESULT)**\n",
    "\n",
    "Training for 1 epoch or a few iterations is totally fine, especially if you run it on cpu. Speed depends on your hardware. You can use Google Colab if you don't have a GPU available, to have a bit more compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load VGG11 with batch normalization (recommended)\n",
    "vgg11 = models.vgg11_bn(pretrained=True)\n",
    "\n",
    "# CIFAR-10 has 10 classes, but VGG was trained on ImageNet (1000 classes)\n",
    "# Replace the final classifier layer\n",
    "num_classes = 10\n",
    "\n",
    "# TODO from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 10.2.2: UNet\n",
    "\n",
    "Now, we want to train another Vision model from scratch again. Moving towards another Vision Task: Image Segmentation. \n",
    "\n",
    "* Implement a super small UNet using convolutional layers. Your model should be around the parameter count 1-2 million. **(RESULT)**\n",
    "* Make sure to use Skip Connections. **(RESULT)**\n",
    "* Train your model on the [Oxford-IIIT Pet Dataset](https://www.robots.ox.ac.uk/~vgg/data/pets/) for image segmentation. **(RESULT)**\n",
    "* Display some segmentation results on test images. **(RESULT)**\n",
    "\n",
    "Feel free to use a subset of the dataset, if you are restricted with memory and/or compute. You will find it in ```./data/pet/```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import OxfordIIITPet\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class SmallUNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Very small U-Net for image segmentation\n",
    "    Input: 128x128x3, Output: 128x128x1 (binary mask)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=3, out_channels=1):\n",
    "        super(SmallUNet, self).__init__()\n",
    "        \n",
    "        # TODO: Define the layers of the UNet\n",
    "    \n",
    "    def forward(self, x):\n",
    "        pass\n",
    "        # TODO: Define the forward pass with skip connections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # EXAMPLE PET SUBSET USAGE\n",
    "\n",
    "# class PetsNPZDataset(Dataset):\n",
    "#     \"\"\"Custom Dataset to load from saved NPZ files\"\"\"\n",
    "    \n",
    "#     def __init__(self, npz_path, transform=None, target_transform=None):\n",
    "#         self.data = np.load(npz_path)\n",
    "#         self.images = self.data['images']\n",
    "#         self.masks = self.data['masks']\n",
    "#         self.transform = transform\n",
    "#         self.target_transform = target_transform\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.images)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         image = self.images[idx]\n",
    "#         mask = self.masks[idx]\n",
    "        \n",
    "#         # Convert to PIL or torch tensor if transforms are provided\n",
    "#         if self.transform:\n",
    "#             image = torch.from_numpy(image).float() / 255.0\n",
    "#             image = image.permute(2, 0, 1)  # (H, W, C) -> (C, H, W)\n",
    "        \n",
    "#         if self.target_transform:\n",
    "#             mask = torch.from_numpy(mask).unsqueeze(0).float()\n",
    "        \n",
    "#         return image, mask\n",
    "\n",
    "# # Load the saved dataset\n",
    "# train_dataset = PetsNPZDataset('./data/pet/pets_train_20percent.npz', transform=True, target_transform=True)\n",
    "# test_dataset = PetsNPZDataset('./data/pet/pets_test_20percent.npz', transform=True, target_transform=True)\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# print(f\"Dataset loaded: {len(train_dataset)} train, {len(test_dataset)} test samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratz, you made it! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyforecast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
