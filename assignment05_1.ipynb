{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5.1 - Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please submit your solution of this notebook in the Whiteboard at the corresponding Assignment entry as .ipynb-file and as .pdf. <br><br>\n",
    "Please do **NOT** rename the file!\n",
    "\n",
    "#### State both names of your group members here:\n",
    "[Jane and John Doe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daniel Thompson, Paola Gega"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Grading Info/Details - Assignment 5.1:\n",
    "\n",
    "The assignment will be graded semi-automatically, which means that your code will be tested against a set of predefined test cases and qualitatively assessed by a human. This will speed up the grading process for us.\n",
    "\n",
    "* For passing the test scripts: \n",
    "    - Please make sure to **NOT** alter predefined class or function names, as this would lead to failing of the test scripts.\n",
    "    - Please do **NOT** rename the files before uploading to the Whiteboard!\n",
    "\n",
    "* **(RESULT)** tags indicate checkpoints that will be specifically assessed by a human.\n",
    "\n",
    "* You will pass the assignment if you pass the majority of test cases and we can at least confirm effort regarding the **(RESULT)**-tagged checkpoints per task.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5.1.1 - Binary Classification Evaluation\n",
    "\n",
    "* Use model implementations of `sklearn` (or other) for Logistic Regression and SVM for classification tasks. Train both models on the `Breast Cancer` dataset. (see given imports) **(RESULT)**\n",
    "* Evaluate the performance of both models using appropriate classification metrics and implement them using `numpy` only. Report at least on the following: accuracy, precision, recall, F1-score. **(RESULT)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful imports\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer, load_diabetes, load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_binary_classification(y_true, y_pred):\n",
    "    # calculate TP, TN, FP, FN\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    TN = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "\n",
    "    # calculate metrics\n",
    "    accuracy = (TP + TN) / len(y_true) if len(y_true) > 0 else 0\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_data = load_breast_cancer()\n",
    "X = breast_cancer_data.data\n",
    "y = breast_cancer_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(breast_cancer_data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Accuracy: 0.9737\n",
      "Precision: 0.9722\n",
      "Recall: 0.9859\n",
      "F1-score: 0.9790\n",
      "\n",
      "SVM Classifier\n",
      "Accuracy: 0.9825\n",
      "Precision: 0.9726\n",
      "Recall: 1.0000\n",
      "F1-score: 0.9861\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(\"Logistic Regression\")\n",
    "log = LogisticRegression()\n",
    "log.fit(X_train, y_train)\n",
    "y_pred_log = log.predict(X_test)\n",
    "log_metrics = metrics_binary_classification(y_test, y_pred_log)\n",
    "print(f\"Accuracy: {log_metrics[0]:.4f}\")\n",
    "print(f\"Precision: {log_metrics[1]:.4f}\")\n",
    "print(f\"Recall: {log_metrics[2]:.4f}\")\n",
    "print(f\"F1-score: {log_metrics[3]:.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"SVM Classifier\")\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred_svc = svc.predict(X_test)\n",
    "svc_metrics = metrics_binary_classification(y_test, y_pred_svc)\n",
    "print(f\"Accuracy: {svc_metrics[0]:.4f}\")\n",
    "print(f\"Precision: {svc_metrics[1]:.4f}\")\n",
    "print(f\"Recall: {svc_metrics[2]:.4f}\")\n",
    "print(f\"F1-score: {svc_metrics[3]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5.1.2 - Multi-Class Classification Evaluation\n",
    "\n",
    "* Do the same as Task 5.1.1 for the multiclass problem `Iris`. Report on the performance metrics: accuracy, precision, recall, F1-score. **(RESULT)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_multiclass_classification(y_true, y_pred, k=3):\n",
    "    TC = np.empty(k)\n",
    "    for i in range(k):\n",
    "        TC[i] = np.sum((y_true == i) & (y_pred == i))\n",
    "\n",
    "    # calculate metrics\n",
    "    accuracy = np.sum(TC) / len(y_true) if len(y_true) > 0 else 0\n",
    "    precision = np.empty(k)\n",
    "    for i in range(k):\n",
    "        precision[i] = TC[i] / np.sum(y_pred == i) if np.sum(y_pred == i) > 0 else 0\n",
    "    recall = np.empty(k)\n",
    "    for i in range(k):\n",
    "        recall[i] = (\n",
    "            np.sum((y_true != i) & (y_pred != i)) \n",
    "            / np.sum(y_true != i)\n",
    "            if np.sum(y_true != i) > 0 else 0 \n",
    "            )\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = load_iris()\n",
    "X = iris_data.data\n",
    "y = iris_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(iris_data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Accuracy: 1.0000\n",
      "Class setosa Precision: 1.0000\n",
      "Class setosa Recall: 1.0000\n",
      "Class setosa F1-score: 1.0000\n",
      "Class versicolor Precision: 1.0000\n",
      "Class versicolor Recall: 1.0000\n",
      "Class versicolor F1-score: 1.0000\n",
      "Class virginica Precision: 1.0000\n",
      "Class virginica Recall: 1.0000\n",
      "Class virginica F1-score: 1.0000\n",
      "\n",
      "SVM Classifier\n",
      "Accuracy: 1.0000\n",
      "Class setosa Precision: 1.0000\n",
      "Class setosa Recall: 1.0000\n",
      "Class setosa F1-score: 1.0000\n",
      "Class versicolor Precision: 1.0000\n",
      "Class versicolor Recall: 1.0000\n",
      "Class versicolor F1-score: 1.0000\n",
      "Class virginica Precision: 1.0000\n",
      "Class virginica Recall: 1.0000\n",
      "Class virginica F1-score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(\"Logistic Regression\")\n",
    "log = LogisticRegression()\n",
    "log.fit(X_train, y_train)\n",
    "y_pred_log = log.predict(X_test)\n",
    "log_metrics = metrics_multiclass_classification(y_test, y_pred_log)\n",
    "print(f\"Accuracy: {log_metrics[0]:.4f}\")\n",
    "for i in range(3):\n",
    "    print(f\"Class {iris_data.target_names[i]} Precision: {log_metrics[1][i]:.4f}\")\n",
    "    print(f\"Class {iris_data.target_names[i]} Recall: {log_metrics[2][i]:.4f}\")\n",
    "    print(f\"Class {iris_data.target_names[i]} F1-score: {log_metrics[3][i]:.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"SVM Classifier\")\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred_svc = svc.predict(X_test)\n",
    "svc_metrics = metrics_multiclass_classification(y_test, y_pred_svc)\n",
    "print(f\"Accuracy: {svc_metrics[0]:.4f}\")\n",
    "for i in range(3):  \n",
    "    print(f\"Class {iris_data.target_names[i]} Precision: {svc_metrics[1][i]:.4f}\")\n",
    "    print(f\"Class {iris_data.target_names[i]} Recall: {svc_metrics[2][i]:.4f}\")\n",
    "    print(f\"Class {iris_data.target_names[i]} F1-score: {svc_metrics[3][i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5.1.3 - Regression Evaluation\n",
    "\n",
    "* Now evaluate a trained `Linear Regression` and `SVM` model for the Regression task `Diabetes`. Report on the performance metrics: MSE, RMSE, MAE, RÂ². **(RESULT)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_data = load_diabetes()\n",
    "X = diabetes_data.data\n",
    "y = diabetes_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(diabetes_data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "MSE: 2900.193628493482\n",
      "RMSE: 53.85344583676593\n",
      "MAE: 42.79409467959994\n",
      "R^2: 0.45260276297191937\n",
      "\n",
      "SVM\n",
      "MSE: 2958.305360860106\n",
      "RMSE: 54.39030576178172\n",
      "MAE: 43.29488016926615\n",
      "R^2: 0.4416344602269302\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(\"Linear Regression\")\n",
    "lin = LinearRegression()\n",
    "lin.fit(X_train, y_train)\n",
    "y_pred_lin = lin.predict(X_test)\n",
    "mse_lin = np.mean((y_pred_lin - y_test)**2)\n",
    "ss_total = np.sum((y_test - np.mean(y_test))**2)\n",
    "print(\"MSE:\", mse_lin)\n",
    "print(\"RMSE:\", np.sqrt(mse_lin))\n",
    "print(\"MAE:\", np.mean(np.abs(y_pred_lin - y_test)))\n",
    "print(\"R^2:\", 1 - np.sum((y_pred_lin - y_test)**2)/ss_total)\n",
    "print()\n",
    "\n",
    "print(\"SVM\")\n",
    "svr = SVR(kernel='sigmoid', C=10, epsilon=0.01, tol=1e-5)\n",
    "svr.fit(X_train, y_train)\n",
    "y_pred_svr = svr.predict(X_test)\n",
    "mse_svr = np.mean((y_pred_svr - y_test)**2)\n",
    "print(\"MSE:\", mse_svr)\n",
    "print(\"RMSE:\", np.sqrt(mse_svr))\n",
    "print(\"MAE:\", np.mean(np.abs(y_pred_svr - y_test)))\n",
    "print(\"R^2:\", 1 - np.sum((y_pred_svr - y_test)**2)/ss_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5.1.4 - Cross-Validation (BONUS)\n",
    "\n",
    "* Set up a cross-validation pipeline for the `Linear Regression` and `SVM` models on the `Diabetes` dataset. (Regression) **(RESULT)**\n",
    "* Set up a cross-validation pipeline for the `Logistic Regression` and `SVM` models on the `Iris` dataset. (Classification) **(RESULT)**\n",
    "* Report the performance metrics on all folds (minimum 5-fold) for each model and dataset. **(RESULT)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Congratz, you made it! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
